{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### ***Convolutional Neural Networks based on MNIST Handwritten Digits**\n",
        "\n",
        "***Aim:-***\n",
        "\n",
        "1.  The main aim of this project is to implement a complete end to end CNN Model based on MNIST Handwritten digits dataset.\n",
        "\n",
        "***Steps used in this Algorithm:-***\n",
        "\n",
        "1.  Import all the necessary libraries\n",
        "\n",
        "2.  Load the MNIST dataset\n",
        "\n",
        "3.  Data preprocessing\n",
        "\n",
        "4.  Build the CNN model\n",
        "\n",
        "5.  Compile the model\n",
        "\n",
        "6.  Train the model\n",
        "\n",
        "7.  Evaluate the model\n",
        "\n",
        "8.  Make predictions\n",
        "\n",
        "9.  Visualize predictions"
      ],
      "metadata": {
        "id": "nF7H-QQuYzm1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 1:  Import all the necessary libraries"
      ],
      "metadata": {
        "id": "itj1fP3kaC1O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import  numpy   as  np\n",
        "import  pandas  as  pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn  as  sns\n",
        "\n",
        "from  tensorflow.keras.datasets  import mnist\n",
        "from  tensorflow.keras.models    import Sequential\n",
        "from  tensorflow.keras.layers    import Dense, Dropout, Conv2D, MaxPooling2D, Flatten\n",
        "from  tensorflow.keras.utils     import to_categorical"
      ],
      "metadata": {
        "id": "B4Pt-LJyaE-9"
      },
      "execution_count": 179,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 2: Load the MNIST dataset"
      ],
      "metadata": {
        "id": "AsaSsJYcbR0D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train, Y_train) , (X_test, Y_test) = mnist.load_data()"
      ],
      "metadata": {
        "id": "QrJfjosYbUEy"
      },
      "execution_count": 180,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vcS2X7wfbcrw",
        "outputId": "596b5e71-fd94-4cb4-9499-5c5d123f62ff"
      },
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]]], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 181
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-luELU2Vbdsh",
        "outputId": "b845896d-f510-489c-f82e-a42542b2fddf"
      },
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]]], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 182
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Shape of the input training data is:\", X_train.shape)\n",
        "print(\"Shape of the input testing data  is:\", X_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YKM3yim-behc",
        "outputId": "aafe0f45-c0c6-43d1-ae81-565a0eed0573"
      },
      "execution_count": 183,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of the input training data is: (60000, 28, 28)\n",
            "Shape of the input testing data  is: (10000, 28, 28)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Shape of the output training data is:\", Y_train.shape)\n",
        "print(\"Shape of the output testing data  is:\", Y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5h6p5rx4crvK",
        "outputId": "67972c7d-bc66-4b9b-ccb7-d5809dfafda1"
      },
      "execution_count": 184,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of the output training data is: (60000,)\n",
            "Shape of the output testing data  is: (10000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### OBSERVATIONS:\n",
        "\n",
        "1. The mnist dataset is loaded.\n",
        "\n",
        "2. Then the mnist dataset is divided into training and testing data.\n",
        "\n",
        "3. The training image data and the testing image data is enclosed in the form of tuples.\n",
        "\n",
        "4. Each image is of the size of 28 * 28 pixels.\n",
        "\n",
        "5. The pixel size values ranges from 0 to 255."
      ],
      "metadata": {
        "id": "lAwNbB0yb6Wi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 3:  Data preprocessing"
      ],
      "metadata": {
        "id": "rs1n_PMFeQ0d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Reshaping the input training and testing data to add the channel dimensions\n",
        "X_train = X_train.reshape(-1,28,28,1)\n",
        "\n",
        "print(X_train.shape)\n",
        "\n",
        "X_test = X_test.reshape(-1,28,28,1)\n",
        "\n",
        "print(X_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "faSXEtvSeUBn",
        "outputId": "339605b3-28e1-498f-cec3-b104d6729984"
      },
      "execution_count": 185,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28, 1)\n",
            "(10000, 28, 28, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### OBSERVATIONS:\n",
        "\n",
        "1. It expects the input training and testing data to be 4D form i.e. (Number of samples, height, width, No of channels)."
      ],
      "metadata": {
        "id": "d-FTLDNUe-Gu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Normalizing the pixel values\n",
        "X_train = X_train/255.0\n",
        "\n",
        "X_test = X_test/255.0"
      ],
      "metadata": {
        "id": "495tvSJ9fRNP"
      },
      "execution_count": 186,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DKv02yobfjkF",
        "outputId": "04cf04d8-ad84-4796-bc1c-ecf4a14cb587"
      },
      "execution_count": 187,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]]],\n",
              "\n",
              "\n",
              "       [[[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]]],\n",
              "\n",
              "\n",
              "       [[[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]]],\n",
              "\n",
              "\n",
              "       ...,\n",
              "\n",
              "\n",
              "       [[[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]]],\n",
              "\n",
              "\n",
              "       [[[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]]],\n",
              "\n",
              "\n",
              "       [[[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]]]])"
            ]
          },
          "metadata": {},
          "execution_count": 187
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7BFryXFnfj9E",
        "outputId": "db72ba48-e664-4490-989e-7e63f497dcb7"
      },
      "execution_count": 188,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]]],\n",
              "\n",
              "\n",
              "       [[[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]]],\n",
              "\n",
              "\n",
              "       [[[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]]],\n",
              "\n",
              "\n",
              "       ...,\n",
              "\n",
              "\n",
              "       [[[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]]],\n",
              "\n",
              "\n",
              "       [[[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]]],\n",
              "\n",
              "\n",
              "       [[[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]]]])"
            ]
          },
          "metadata": {},
          "execution_count": 188
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### OBSERVATIONS:\n",
        "\n",
        "1. Every pixel value is in the form of 0 to 255.\n",
        "\n",
        "2. Each pixel value is divided by 255.0 so as to normalize the pixel value.\n",
        "\n",
        "3. This normalization is done so that the neural network model can be easily be trained when the pixel values are small and consistent.\n",
        "\n",
        "4. This normalization is done so that the model can be easilt be trained and aster convergence can happen easily."
      ],
      "metadata": {
        "id": "g228grhUftdg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Y_train = to_categorical(Y_train, num_classes=10)"
      ],
      "metadata": {
        "id": "hlh3mQTsgFuC"
      },
      "execution_count": 189,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ltb1Uu4QgM1b",
        "outputId": "1df1df51-65d7-4235-c77d-f9c55e949bb2"
      },
      "execution_count": 190,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [1., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 1., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 190
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y_test = to_categorical(Y_test, num_classes=10)"
      ],
      "metadata": {
        "id": "JqRJqg8zgUie"
      },
      "execution_count": 191,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-HA1lZNlgU5Z",
        "outputId": "ebd4ba6d-f26f-42df-9b8c-d4223f676bee"
      },
      "execution_count": 192,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 1., 0., 0.],\n",
              "       [0., 0., 1., ..., 0., 0., 0.],\n",
              "       [0., 1., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 192
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### OBSERVATIONS:\n",
        "\n",
        "1. One Hot Encoding is performed on the output data as the model predicts the output in the form of probabilities. So the Actual Output can be easily be compared with the predicted one.\n",
        "\n",
        "2. It cannot be happened with a single number."
      ],
      "metadata": {
        "id": "HdIDG7ZggYC4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 4: Build the CNN model"
      ],
      "metadata": {
        "id": "Xag-ne89nxK8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Create an object for CNN Model\n",
        "\n",
        "model = Sequential([\n",
        "    ### create the first layer for Convolutional and Max Pooling\n",
        "    Conv2D(filters=32, kernel_size=(3,3), activation='relu', input_shape=(28,28,1))                            ,\n",
        "    MaxPooling2D(pool_size=(2,2))                                                                              ,\n",
        "\n",
        "    ### create the second dense layer for Convolutional and Max Pooling\n",
        "    Conv2D(filters=64,kernel_size=(3,3), activation='relu')                                                    ,\n",
        "    MaxPooling2D(pool_size=(2,2))                                                                              ,\n",
        "\n",
        "    ### Convert the feature maps into 1D vector\n",
        "    Flatten()                                                                                                  ,\n",
        "    ### Create a fully connected dense layer\n",
        "    Dense(128, activation='relu')                                                                              ,\n",
        "    ### Add the dropout function to reduce the overfitting\n",
        "    Dropout(0.2)                                                                                               ,\n",
        "    ### Add the final output layer\n",
        "    Dense(10, activation = 'softmax')\n",
        "])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fvskQOZDnzDM",
        "outputId": "f8d8a3fd-93e0-45d4-e8df-f7f66dc0eb20"
      },
      "execution_count": 193,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### OBSERVATIONS:\n",
        "\n",
        "1. We have an input image of the shape of 28 * 28 * 1.\n",
        "\n",
        "2. In the first layer, Convolution is applied on the input image of the size (28 * 28 * 1) followed by Relu activation function so as to produce 32 feature maps of the size 3 * 3.\n",
        "\n",
        "3. Then Max Pooling is applied on the feature maps to form pooled feature maps by selecting the maximum values from each 2 * 2 window .\n",
        "\n",
        "4. In the second layer, Convolution is again applied along with the ReLU Activation function resulting in 64 feature maps of the size 3 * 3.\n",
        "\n",
        "5. Then max pooling is applied on the feature maps to get the pooled feature maps by selecting the maximum value from each 2 * 2 window.\n",
        "\n",
        "6. Flattening is applied on the pooled feature maps to convert it into 1D vector.\n",
        "\n",
        "7. Then a fully connected dense neural network is formed along with 128 neurons along with relu activation function applied on it\n",
        "\n",
        "8. Dropout is applied on it to reduce overfitting.\n",
        "\n",
        "9. Then a final output layer is added that has 10 neurons along with sotmax activation function applied on it to get the probability of each output class."
      ],
      "metadata": {
        "id": "Z3U8BM2OpXkI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 5: Compile the model"
      ],
      "metadata": {
        "id": "f4y_vRZwueEm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    optimizer  =  'adam'                              ,\n",
        "    loss       =  'categorical_crossentropy'          ,\n",
        "    metrics    =  ['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "_MN0rYlcuf7E"
      },
      "execution_count": 194,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 6:  Train the model"
      ],
      "metadata": {
        "id": "2OdAUm4guz5Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    X_train                   ,\n",
        "    Y_train                   ,\n",
        "    epochs     = 10           ,\n",
        "    batch_size = 128          ,\n",
        "    validation_split = 0.1    ,\n",
        "    verbose    = 1\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fnk0q9K5u1zG",
        "outputId": "3490dd9e-5cf2-4764-cf6e-e51c91529e88"
      },
      "execution_count": 195,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 107ms/step - accuracy: 0.8344 - loss: 0.5564 - val_accuracy: 0.9835 - val_loss: 0.0578\n",
            "Epoch 2/10\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 102ms/step - accuracy: 0.9771 - loss: 0.0778 - val_accuracy: 0.9893 - val_loss: 0.0475\n",
            "Epoch 3/10\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 100ms/step - accuracy: 0.9833 - loss: 0.0524 - val_accuracy: 0.9875 - val_loss: 0.0433\n",
            "Epoch 4/10\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 107ms/step - accuracy: 0.9878 - loss: 0.0387 - val_accuracy: 0.9898 - val_loss: 0.0374\n",
            "Epoch 5/10\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 103ms/step - accuracy: 0.9893 - loss: 0.0317 - val_accuracy: 0.9903 - val_loss: 0.0368\n",
            "Epoch 6/10\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 99ms/step - accuracy: 0.9912 - loss: 0.0269 - val_accuracy: 0.9905 - val_loss: 0.0390\n",
            "Epoch 7/10\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 100ms/step - accuracy: 0.9933 - loss: 0.0224 - val_accuracy: 0.9905 - val_loss: 0.0356\n",
            "Epoch 8/10\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 101ms/step - accuracy: 0.9936 - loss: 0.0190 - val_accuracy: 0.9927 - val_loss: 0.0302\n",
            "Epoch 9/10\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 99ms/step - accuracy: 0.9942 - loss: 0.0166 - val_accuracy: 0.9917 - val_loss: 0.0350\n",
            "Epoch 10/10\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 102ms/step - accuracy: 0.9946 - loss: 0.0156 - val_accuracy: 0.9912 - val_loss: 0.0375\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### OBSERVATIONS:\n",
        "\n",
        "1. After performing the model training, the accuracy of the model has inproved and the loss function has reduced a lot. So the model is working fine."
      ],
      "metadata": {
        "id": "GJBiPTUExsov"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 7: Evaluate the model"
      ],
      "metadata": {
        "id": "H12N6oeTyCEM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print(\"Test Accuracy:\", test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "quFHWOisyERj",
        "outputId": "bc87dccc-1057-4f51-a7c9-57f52b2aea7a"
      },
      "execution_count": 196,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.9914000034332275\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### OBSERVATIONS:\n",
        "\n",
        "1. The test accuracy of the model is very high."
      ],
      "metadata": {
        "id": "I9BpSlZ3zNvN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 8:  Make predictions"
      ],
      "metadata": {
        "id": "bEGN6K1XyPz7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Y_pred_prob = model.predict(X_test)  ### get the probabilities for all the classes\n",
        "\n",
        "### Convert the probabilities into the labels\n",
        "Y_pred = np.argmax(Y_pred_prob, axis=1)\n",
        "\n",
        "Y_true = Y_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oxWLo6g3yUCs",
        "outputId": "6267a9f7-e21d-4f73-eb2f-7b9ce88d518b"
      },
      "execution_count": 197,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### OBSERVATIONS:\n",
        "\n",
        "1. argmax returns the index of the maximum probability value from the array and depicts the index value as the label."
      ],
      "metadata": {
        "id": "YZXsw9dlzUj-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 9: Visualize Predictions"
      ],
      "metadata": {
        "id": "e9UrjiybyoC2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,4))\n",
        "\n",
        "for i in range(5):\n",
        "    plt.subplot(1,5,i+1)\n",
        "    plt.imshow(X_test[i].reshape(28,28), cmap='gray')\n",
        "    plt.title(f\"Pred: {Y_pred[i]}\")\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192
        },
        "id": "gI6BXMkxyrmv",
        "outputId": "88c36dbe-8633-4554-f861-a2f5505deae0"
      },
      "execution_count": 199,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x400 with 5 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}