{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Recurrent Neural Networks (LSTM) based on IMDB Movie Dataset**\n",
        "\n",
        "**Aim:-**\n",
        "\n",
        "1.  The main aim of this project is to perform the sentimental analysis on the imdb movie dataset using LSTM(Long Short Term Memory) and check whether the movie review is positive or negative.\n",
        "\n",
        "2.  This is done by implementing the Recurrent Neural Networks.\n",
        "\n",
        "\n",
        "**Steps for implementing Recurrent Neural Networks on IMDB Movie Review Dataset:-**\n",
        "\n",
        "1.  Import all the necessary libraries\n",
        "\n",
        "2.  Load Dataset\n",
        "\n",
        "3.  Perform the Pad Sequences\n",
        "\n",
        "4.  Build the RNN Model\n",
        "\n",
        "5.  Compile the RNN Model\n",
        "\n",
        "6.  Train the RNN Model\n",
        "\n",
        "7.  Evaluate the RNN Model\n",
        "\n",
        "8.  Make Predictions on Custom Text\n",
        "\n",
        "**Dataset Description:-**\n",
        "\n",
        "\n",
        "1.  The imdb movie review dataset is a balanced labelled dataset that has 50000 labelled reviews.\n",
        "\n",
        "2.  It has 25000 training labelled reviews and 25000 testing labelled reviews."
      ],
      "metadata": {
        "id": "6Fdu2Uw_3l0u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 1: Import all the necessary libraries"
      ],
      "metadata": {
        "id": "IXFzbvmo5C1l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import  numpy              as   np\n",
        "import  pandas             as  pd\n",
        "import  matplotlib.pyplot  as  plt\n",
        "import  seaborn            as  sns\n",
        "\n",
        "\n",
        "import tensorflow                               as     tf\n",
        "from   tensorflow.keras.datasets                import imdb\n",
        "from   tensorflow.keras.preprocessing.sequence  import pad_sequences\n",
        "from   tensorflow.keras.models                  import Sequential\n",
        "from   tensorflow.keras.layers                  import Dense, Dropout, BatchNormalization,Embedding,LSTM"
      ],
      "metadata": {
        "id": "_zHQO7Jd5EUi"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**OBSERVATIONS:**\n",
        "\n",
        "1.    numpy   -------------->    Computation of the numerical array\n",
        "\n",
        "2.    pandas  -------------->    Data Creation and Manipulation\n",
        "\n",
        "3.    matplotlib ----------->    Data Visualization\n",
        "\n",
        "4.    seaborn  ------------->    Data Correlation\n",
        "\n",
        "5.    tensorflow ----------->    Deep Learning Framework\n",
        "\n",
        "6.    imdb     ------------->    Movie Review dataset that has 50000 labels\n",
        "\n",
        "7.    pad_sequences -------->    makes all the input sequences of equal length\n",
        "\n",
        "8.    Sequential ----------->    forms linear stacks of layers\n",
        "\n",
        "9.    Embedding  ----------->   It forms the embedding layer of RNN by converting the integer encoded words into the dense vectors.\n",
        "\n",
        "10.    SimpleRNN ----------->  It forms Simple Recurrent Neural Networks by capturing one word at the time and captures its temporal information. It uses the information of the past state and predicts the future state.\n",
        "\n",
        "11.   Flatten  -------------> converts the 2D / 3D feature maps into 1D vectors.\n",
        "\n",
        "12.   Dense    -------------> forms the dense neural network model\n",
        "\n",
        "13.   Dropout   ------------> Reduces the overfitting\n",
        "\n",
        "14.   BatchNormalization ---------> normalized the activation"
      ],
      "metadata": {
        "id": "vRBtL0ES6Cr0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 2: Load Dataset"
      ],
      "metadata": {
        "id": "zsSGq7TL6cpl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### define the vocabulary size\n",
        "voc_size = 10000\n",
        "\n",
        "(X_train, Y_train),(X_test, Y_test)=imdb.load_data(num_words=voc_size)"
      ],
      "metadata": {
        "id": "g59oFluL7frt"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Input Data:**"
      ],
      "metadata": {
        "id": "mKQ3zQZN8EQy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1DsZLah7_oQ",
        "outputId": "1c873c56-fd0d-4696-8e14-c31be435b888"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([list([1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]),\n",
              "       list([1, 194, 1153, 194, 8255, 78, 228, 5, 6, 1463, 4369, 5012, 134, 26, 4, 715, 8, 118, 1634, 14, 394, 20, 13, 119, 954, 189, 102, 5, 207, 110, 3103, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2300, 1523, 5, 647, 4, 116, 9, 35, 8163, 4, 229, 9, 340, 1322, 4, 118, 9, 4, 130, 4901, 19, 4, 1002, 5, 89, 29, 952, 46, 37, 4, 455, 9, 45, 43, 38, 1543, 1905, 398, 4, 1649, 26, 6853, 5, 163, 11, 3215, 2, 4, 1153, 9, 194, 775, 7, 8255, 2, 349, 2637, 148, 605, 2, 8003, 15, 123, 125, 68, 2, 6853, 15, 349, 165, 4362, 98, 5, 4, 228, 9, 43, 2, 1157, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 4373, 228, 8255, 5, 2, 656, 245, 2350, 5, 4, 9837, 131, 152, 491, 18, 2, 32, 7464, 1212, 14, 9, 6, 371, 78, 22, 625, 64, 1382, 9, 8, 168, 145, 23, 4, 1690, 15, 16, 4, 1355, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95]),\n",
              "       list([1, 14, 47, 8, 30, 31, 7, 4, 249, 108, 7, 4, 5974, 54, 61, 369, 13, 71, 149, 14, 22, 112, 4, 2401, 311, 12, 16, 3711, 33, 75, 43, 1829, 296, 4, 86, 320, 35, 534, 19, 263, 4821, 1301, 4, 1873, 33, 89, 78, 12, 66, 16, 4, 360, 7, 4, 58, 316, 334, 11, 4, 1716, 43, 645, 662, 8, 257, 85, 1200, 42, 1228, 2578, 83, 68, 3912, 15, 36, 165, 1539, 278, 36, 69, 2, 780, 8, 106, 14, 6905, 1338, 18, 6, 22, 12, 215, 28, 610, 40, 6, 87, 326, 23, 2300, 21, 23, 22, 12, 272, 40, 57, 31, 11, 4, 22, 47, 6, 2307, 51, 9, 170, 23, 595, 116, 595, 1352, 13, 191, 79, 638, 89, 2, 14, 9, 8, 106, 607, 624, 35, 534, 6, 227, 7, 129, 113]),\n",
              "       ...,\n",
              "       list([1, 11, 6, 230, 245, 6401, 9, 6, 1225, 446, 2, 45, 2174, 84, 8322, 4007, 21, 4, 912, 84, 2, 325, 725, 134, 2, 1715, 84, 5, 36, 28, 57, 1099, 21, 8, 140, 8, 703, 5, 2, 84, 56, 18, 1644, 14, 9, 31, 7, 4, 9406, 1209, 2295, 2, 1008, 18, 6, 20, 207, 110, 563, 12, 8, 2901, 2, 8, 97, 6, 20, 53, 4767, 74, 4, 460, 364, 1273, 29, 270, 11, 960, 108, 45, 40, 29, 2961, 395, 11, 6, 4065, 500, 7, 2, 89, 364, 70, 29, 140, 4, 64, 4780, 11, 4, 2678, 26, 178, 4, 529, 443, 2, 5, 27, 710, 117, 2, 8123, 165, 47, 84, 37, 131, 818, 14, 595, 10, 10, 61, 1242, 1209, 10, 10, 288, 2260, 1702, 34, 2901, 2, 4, 65, 496, 4, 231, 7, 790, 5, 6, 320, 234, 2766, 234, 1119, 1574, 7, 496, 4, 139, 929, 2901, 2, 7750, 5, 4241, 18, 4, 8497, 2, 250, 11, 1818, 7561, 4, 4217, 5408, 747, 1115, 372, 1890, 1006, 541, 9303, 7, 4, 59, 2, 4, 3586, 2]),\n",
              "       list([1, 1446, 7079, 69, 72, 3305, 13, 610, 930, 8, 12, 582, 23, 5, 16, 484, 685, 54, 349, 11, 4120, 2959, 45, 58, 1466, 13, 197, 12, 16, 43, 23, 2, 5, 62, 30, 145, 402, 11, 4131, 51, 575, 32, 61, 369, 71, 66, 770, 12, 1054, 75, 100, 2198, 8, 4, 105, 37, 69, 147, 712, 75, 3543, 44, 257, 390, 5, 69, 263, 514, 105, 50, 286, 1814, 23, 4, 123, 13, 161, 40, 5, 421, 4, 116, 16, 897, 13, 2, 40, 319, 5872, 112, 6700, 11, 4803, 121, 25, 70, 3468, 4, 719, 3798, 13, 18, 31, 62, 40, 8, 7200, 4, 2, 7, 14, 123, 5, 942, 25, 8, 721, 12, 145, 5, 202, 12, 160, 580, 202, 12, 6, 52, 58, 2, 92, 401, 728, 12, 39, 14, 251, 8, 15, 251, 5, 2, 12, 38, 84, 80, 124, 12, 9, 23]),\n",
              "       list([1, 17, 6, 194, 337, 7, 4, 204, 22, 45, 254, 8, 106, 14, 123, 4, 2, 270, 2, 5, 2, 2, 732, 2098, 101, 405, 39, 14, 1034, 4, 1310, 9, 115, 50, 305, 12, 47, 4, 168, 5, 235, 7, 38, 111, 699, 102, 7, 4, 4039, 9245, 9, 24, 6, 78, 1099, 17, 2345, 2, 21, 27, 9685, 6139, 5, 2, 1603, 92, 1183, 4, 1310, 7, 4, 204, 42, 97, 90, 35, 221, 109, 29, 127, 27, 118, 8, 97, 12, 157, 21, 6789, 2, 9, 6, 66, 78, 1099, 4, 631, 1191, 5, 2642, 272, 191, 1070, 6, 7585, 8, 2197, 2, 2, 544, 5, 383, 1271, 848, 1468, 2, 497, 2, 8, 1597, 8778, 2, 21, 60, 27, 239, 9, 43, 8368, 209, 405, 10, 10, 12, 764, 40, 4, 248, 20, 12, 16, 5, 174, 1791, 72, 7, 51, 6, 1739, 22, 4, 204, 131, 9])],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jps6TCoq8AJr",
        "outputId": "2ff1242a-4ba0-42e5-e21a-89df832fbe0b"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([list([1, 591, 202, 14, 31, 6, 717, 10, 10, 2, 2, 5, 4, 360, 7, 4, 177, 5760, 394, 354, 4, 123, 9, 1035, 1035, 1035, 10, 10, 13, 92, 124, 89, 488, 7944, 100, 28, 1668, 14, 31, 23, 27, 7479, 29, 220, 468, 8, 124, 14, 286, 170, 8, 157, 46, 5, 27, 239, 16, 179, 2, 38, 32, 25, 7944, 451, 202, 14, 6, 717]),\n",
              "       list([1, 14, 22, 3443, 6, 176, 7, 5063, 88, 12, 2679, 23, 1310, 5, 109, 943, 4, 114, 9, 55, 606, 5, 111, 7, 4, 139, 193, 273, 23, 4, 172, 270, 11, 7216, 2, 4, 8463, 2801, 109, 1603, 21, 4, 22, 3861, 8, 6, 1193, 1330, 10, 10, 4, 105, 987, 35, 841, 2, 19, 861, 1074, 5, 1987, 2, 45, 55, 221, 15, 670, 5304, 526, 14, 1069, 4, 405, 5, 2438, 7, 27, 85, 108, 131, 4, 5045, 5304, 3884, 405, 9, 3523, 133, 5, 50, 13, 104, 51, 66, 166, 14, 22, 157, 9, 4, 530, 239, 34, 8463, 2801, 45, 407, 31, 7, 41, 3778, 105, 21, 59, 299, 12, 38, 950, 5, 4521, 15, 45, 629, 488, 2733, 127, 6, 52, 292, 17, 4, 6936, 185, 132, 1988, 5304, 1799, 488, 2693, 47, 6, 392, 173, 4, 2, 4378, 270, 2352, 4, 1500, 7, 4, 65, 55, 73, 11, 346, 14, 20, 9, 6, 976, 2078, 7, 5293, 861, 2, 5, 4182, 30, 3127, 2, 56, 4, 841, 5, 990, 692, 8, 4, 1669, 398, 229, 10, 10, 13, 2822, 670, 5304, 14, 9, 31, 7, 27, 111, 108, 15, 2033, 19, 7836, 1429, 875, 551, 14, 22, 9, 1193, 21, 45, 4829, 5, 45, 252, 8, 2, 6, 565, 921, 3639, 39, 4, 529, 48, 25, 181, 8, 67, 35, 1732, 22, 49, 238, 60, 135, 1162, 14, 9, 290, 4, 58, 10, 10, 472, 45, 55, 878, 8, 169, 11, 374, 5687, 25, 203, 28, 8, 818, 12, 125, 4, 3077]),\n",
              "       list([1, 111, 748, 4368, 1133, 2, 2, 4, 87, 1551, 1262, 7, 31, 318, 9459, 7, 4, 498, 5076, 748, 63, 29, 5161, 220, 686, 2, 5, 17, 12, 575, 220, 2507, 17, 6, 185, 132, 2, 16, 53, 928, 11, 2, 74, 4, 438, 21, 27, 2, 589, 8, 22, 107, 2, 2, 997, 1638, 8, 35, 2076, 9019, 11, 22, 231, 54, 29, 1706, 29, 100, 2, 2425, 34, 2, 8738, 2, 5, 2, 98, 31, 2122, 33, 6, 58, 14, 3808, 1638, 8, 4, 365, 7, 2789, 3761, 356, 346, 4, 2, 1060, 63, 29, 93, 11, 5421, 11, 2, 33, 6, 58, 54, 1270, 431, 748, 7, 32, 2580, 16, 11, 94, 2, 10, 10, 4, 993, 2, 7, 4, 1766, 2634, 2164, 2, 8, 847, 8, 1450, 121, 31, 7, 27, 86, 2663, 2, 16, 6, 465, 993, 2006, 2, 573, 17, 2, 42, 4, 2, 37, 473, 6, 711, 6, 8869, 7, 328, 212, 70, 30, 258, 11, 220, 32, 7, 108, 21, 133, 12, 9, 55, 465, 849, 3711, 53, 33, 2071, 1969, 37, 70, 1144, 4, 5940, 1409, 74, 476, 37, 62, 91, 1329, 169, 4, 1330, 2, 146, 655, 2212, 5, 258, 12, 184, 2, 546, 5, 849, 2, 7, 4, 22, 1436, 18, 631, 1386, 797, 7, 4, 8712, 71, 348, 425, 4320, 1061, 19, 2, 5, 2, 11, 661, 8, 339, 2, 4, 2455, 2, 7, 4, 1962, 10, 10, 263, 787, 9, 270, 11, 6, 9466, 4, 2, 2, 121, 4, 5437, 26, 4434, 19, 68, 1372, 5, 28, 446, 6, 318, 7149, 8, 67, 51, 36, 70, 81, 8, 4392, 2294, 36, 1197, 8, 2, 2, 18, 6, 711, 4, 9909, 26, 2, 1125, 11, 14, 636, 720, 12, 426, 28, 77, 776, 8, 97, 38, 111, 7489, 6175, 168, 1239, 5189, 137, 2, 18, 27, 173, 9, 2399, 17, 6, 2, 428, 2, 232, 11, 4, 8014, 37, 272, 40, 2708, 247, 30, 656, 6, 2, 54, 2, 3292, 98, 6, 2840, 40, 558, 37, 6093, 98, 4, 2, 1197, 15, 14, 9, 57, 4893, 5, 4659, 6, 275, 711, 7937, 2, 3292, 98, 6, 2, 10, 10, 6639, 19, 14, 2, 267, 162, 711, 37, 5900, 752, 98, 4, 2, 2378, 90, 19, 6, 2, 7, 2, 1810, 2, 4, 4770, 3183, 930, 8, 508, 90, 4, 1317, 8, 4, 2, 17, 2, 3965, 1853, 4, 1494, 8, 4468, 189, 4, 2, 6287, 5774, 4, 4770, 5, 95, 271, 23, 6, 7742, 6063, 2, 5437, 33, 1526, 6, 425, 3155, 2, 4535, 1636, 7, 4, 4669, 2, 469, 4, 4552, 54, 4, 150, 5664, 2, 280, 53, 2, 2, 18, 339, 29, 1978, 27, 7885, 5, 2, 68, 1830, 19, 6571, 2, 4, 1515, 7, 263, 65, 2132, 34, 6, 5680, 7489, 43, 159, 29, 9, 4706, 9, 387, 73, 195, 584, 10, 10, 1069, 4, 58, 810, 54, 14, 6078, 117, 22, 16, 93, 5, 1069, 4, 192, 15, 12, 16, 93, 34, 6, 1766, 2, 33, 4, 5673, 7, 15, 2, 9252, 3286, 325, 12, 62, 30, 776, 8, 67, 14, 17, 6, 2, 44, 148, 687, 2, 203, 42, 203, 24, 28, 69, 2, 6676, 11, 330, 54, 29, 93, 2, 21, 845, 2, 27, 1099, 7, 819, 4, 22, 1407, 17, 6, 2, 787, 7, 2460, 2, 2, 100, 30, 4, 3737, 3617, 3169, 2321, 42, 1898, 11, 4, 3814, 42, 101, 704, 7, 101, 999, 15, 1625, 94, 2926, 180, 5, 9, 9101, 34, 2, 45, 6, 1429, 22, 60, 6, 1220, 31, 11, 94, 6408, 96, 21, 94, 749, 9, 57, 975]),\n",
              "       ...,\n",
              "       list([1, 13, 1408, 15, 8, 135, 14, 9, 35, 32, 46, 394, 20, 62, 30, 5093, 21, 45, 184, 78, 4, 1492, 910, 769, 2290, 2515, 395, 4257, 5, 1454, 11, 119, 2, 89, 1036, 4, 116, 218, 78, 21, 407, 100, 30, 128, 262, 15, 7, 185, 2280, 284, 1842, 2, 37, 315, 4, 226, 20, 272, 2942, 40, 29, 152, 60, 181, 8, 30, 50, 553, 362, 80, 119, 12, 21, 846, 5518]),\n",
              "       list([1, 11, 119, 241, 9, 4, 840, 20, 12, 468, 15, 94, 3684, 562, 791, 39, 4, 86, 107, 8, 97, 14, 31, 33, 4, 2960, 7, 743, 46, 1028, 9, 3531, 5, 4, 768, 47, 8, 79, 90, 145, 164, 162, 50, 6, 501, 119, 7, 9, 4, 78, 232, 15, 16, 224, 11, 4, 333, 20, 4, 985, 200, 5, 2, 5, 9, 1861, 8, 79, 357, 4, 20, 47, 220, 57, 206, 139, 11, 12, 5, 55, 117, 212, 13, 1276, 92, 124, 51, 45, 1188, 71, 536, 13, 520, 14, 20, 6, 2302, 7, 470]),\n",
              "       list([1, 6, 52, 7465, 430, 22, 9, 220, 2594, 8, 28, 2, 519, 3227, 6, 769, 15, 47, 6, 3482, 4067, 8, 114, 5, 33, 222, 31, 55, 184, 704, 5586, 2, 19, 346, 3153, 5, 6, 364, 350, 4, 184, 5586, 9, 133, 1810, 11, 5417, 2, 21, 4, 7298, 2, 570, 50, 2005, 2643, 9, 6, 1249, 17, 6, 2, 2, 21, 17, 6, 1211, 232, 1138, 2249, 29, 266, 56, 96, 346, 194, 308, 9, 194, 21, 29, 218, 1078, 19, 4, 78, 173, 7, 27, 2, 5698, 3406, 718, 2, 9, 6, 6907, 17, 210, 5, 3281, 5677, 47, 77, 395, 14, 172, 173, 18, 2740, 2931, 4517, 82, 127, 27, 173, 11, 6, 392, 217, 21, 50, 9, 57, 65, 12, 2, 53, 40, 35, 390, 7, 11, 4, 3567, 7, 4, 314, 74, 6, 792, 22, 2, 19, 714, 727, 5205, 382, 4, 91, 6533, 439, 19, 14, 20, 9, 1441, 5805, 1118, 4, 756, 25, 124, 4, 31, 12, 16, 93, 804, 34, 2005, 2643])],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Shape of the input training data is:\", X_train.shape)\n",
        "print(\"Shape of the input testing  data is:\", X_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fYwi4qVg8KvT",
        "outputId": "a56a2bb8-7c8a-4e2f-a05c-b20df6eddfc3"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of the input training data is: (25000,)\n",
            "Shape of the input testing  data is: (25000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Output Data:**"
      ],
      "metadata": {
        "id": "XDPsYGbd8I0E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Y_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FFcC9_NE8BLg",
        "outputId": "a917d1da-bc2b-460b-ede0-cda122168a44"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 0, ..., 0, 1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "huz3wsO-8C5F",
        "outputId": "3033c24a-9388-43c6-d6a2-d7be99cc0e27"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 1, ..., 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Shape of the output training data is:\", Y_train.shape)\n",
        "print(\"Shape of the output testing  data is:\", Y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X-f2mlj48TyK",
        "outputId": "a8acec20-328c-4d94-dee2-733721f81f4c"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of the output training data is: (25000,)\n",
            "Shape of the output testing  data is: (25000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **OBSERVATIONS:**\n",
        "\n",
        "1. The imdb dataset is loaded.\n",
        "\n",
        "2. The maximum number of words in the imdb dataset is restricted to 10000 vocabulary words as this imdb dataset load data function considers only top 10000 most frequent words.\n",
        "\n",
        "3. Each movie review in the imdb dataset contains only the positive review or the negative review.\n",
        "\n",
        "4. The imdb movie review dataset is divided into the training data and the testing data.\n",
        "\n",
        "5. Out of 50000 data records in the imdb movie review dataset, it has\n",
        "\n",
        "    (a.)   25000  training reviews\n",
        "\n",
        "    (b.)   25000  testing reviews"
      ],
      "metadata": {
        "id": "yn0EmMdC8eQs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 3: Perform the Pad Sequences"
      ],
      "metadata": {
        "id": "_vp_3g7t90c4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Shape of the input data before padding:**"
      ],
      "metadata": {
        "id": "UHQCMTXT-bUh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Shape of the input training data before padding:\", X_train.shape)\n",
        "print(\"Shape of the input testing  data before padding:\", X_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7XCN7Lza-ab4",
        "outputId": "64303a10-34e5-4df1-a00d-2b6c0518f6f0"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of the input training data before padding: (25000,)\n",
            "Shape of the input testing  data before padding: (25000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Perform Padding on the inputs:**"
      ],
      "metadata": {
        "id": "eGcwb1H9-rTo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### define the max length for padding\n",
        "max_len = 200\n",
        "\n",
        "X_train = pad_sequences(X_train, maxlen=max_len)\n",
        "\n",
        "X_test = pad_sequences(X_test, maxlen=max_len)"
      ],
      "metadata": {
        "id": "Z1LXWDL_-w9Z"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Shape of the input data after padding:**"
      ],
      "metadata": {
        "id": "tVTH-0_5_E_2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7x54H_s7_Vvs",
        "outputId": "6acb3ec1-e438-4c5f-a989-96687c333d9d"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   5,   25,  100, ...,   19,  178,   32],\n",
              "       [   0,    0,    0, ...,   16,  145,   95],\n",
              "       [   0,    0,    0, ...,    7,  129,  113],\n",
              "       ...,\n",
              "       [   0,    0,    0, ...,    4, 3586,    2],\n",
              "       [   0,    0,    0, ...,   12,    9,   23],\n",
              "       [   0,    0,    0, ...,  204,  131,    9]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P__8jNli_W9s",
        "outputId": "5a4ed833-84bc-4d29-e34c-8cabc1073809"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   0,    0,    0, ...,   14,    6,  717],\n",
              "       [1987,    2,   45, ...,  125,    4, 3077],\n",
              "       [4468,  189,    4, ...,    9,   57,  975],\n",
              "       ...,\n",
              "       [   0,    0,    0, ...,   21,  846, 5518],\n",
              "       [   0,    0,    0, ..., 2302,    7,  470],\n",
              "       [   0,    0,    0, ...,   34, 2005, 2643]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Shape of the input training data after padding:\", X_train.shape)\n",
        "print(\"Shape of the input testing  data after padding:\", X_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uO-TJU1q_KDw",
        "outputId": "a3115879-b003-488a-e635-e728c22a4cee"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of the input training data after padding: (25000, 200)\n",
            "Shape of the input testing  data after padding: (25000, 200)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**OBSERVATIONS:**\n",
        "\n",
        "1. Padding is applied on the inputs to bring all its sequences to the equal length.\n",
        "\n",
        "2. This is because the RNN can only work with the fixed lengtn input sequences.\n",
        "\n",
        "3. Padding can be applied in two ways:-\n",
        "\n",
        "   (a.)  Pre-padding -----> Applying zeros at the beginning of the input sequence.\n",
        "\n",
        "   (b.)  Post-padding -----> Applying zeros at the end of the input sequence."
      ],
      "metadata": {
        "id": "Mz9rmwp7_agG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 4: Build the RNN Model"
      ],
      "metadata": {
        "id": "EY7oVNRKAde3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Construct the RNN Model\n",
        "\n",
        "model = Sequential([\n",
        "    ### Construct an Embedding layer\n",
        "    Embedding(input_dim=10000, output_dim=128,input_length = max_len)           ,\n",
        "    ### Constrcut the LSTM Layer\n",
        "    LSTM(128)                                                                   ,\n",
        "    ### Construct the output layer\n",
        "    Dense(1, activation = 'sigmoid')\n",
        "])"
      ],
      "metadata": {
        "id": "NLQDq0QTDoav"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**OBSERVATIONS:**\n",
        "\n",
        "1.   A Sequential model for LSTM RNN is built.\n",
        "\n",
        "2.   Then the embedding layer is built on the top of Sequential RNN Model.\n",
        "\n",
        "      (a.)  This embedding layer contains 10000 most frequent words as input.\n",
        "\n",
        "      (b.)  Each word is converted into 128 dense dimensional vectors and each vector is of the length of 200.\n",
        "\n",
        "3.   LSTM layer is applied on 128 dense dimensional vectors\n",
        "\n",
        "      (a.)  LSTM solves the problem of vanishing gradient descent.\n",
        "\n",
        "      (b.)  It remembers the long term dependencies i.e  the event that has happened long back\n",
        "\n",
        "      (c.)  Based on it, it can predict the future word.\n",
        "\n",
        "\n",
        "4.   The final output layer is costructed with 1 hidden neuron and sigmoid activation function is applied in it to predict whether the movie review is positive or negative."
      ],
      "metadata": {
        "id": "XpQxsd1NCGdk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### get the summary of the model\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "piYZdum9EMr7",
        "outputId": "29d5a138-a928-4041-f5b1-e5bf6af9f22b"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 5: Compile the RNN Model"
      ],
      "metadata": {
        "id": "aN2SPGkoEUDu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    optimizer   =  'adam'                        ,\n",
        "    loss        =  'binary_crossentropy'         ,\n",
        "    metrics     =   ['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "NM_q-ndLEWAa"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **OBSEVATIONS:**\n",
        "\n",
        "1. The RNN Model has been made ready for the training with the help of the following parameters:-\n",
        "\n",
        " (a.)   optimizer = 'adam'   -----> It optimizes the weights during the training of the model.\n",
        "\n",
        " (b.)    loss       =  'binary_cossentropy'  -----> It is used to solve the binay classification poblem\n",
        "\n",
        " (c.)    metrics = ['accuracy'] -------> It is used to evaluate the performance of the model."
      ],
      "metadata": {
        "id": "A7d4lwvMEnL6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 6: Train the RNN Model"
      ],
      "metadata": {
        "id": "czFA9DBeEuMD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    X_train                                            ,\n",
        "    Y_train                                            ,\n",
        "    epochs                  =   3                      ,\n",
        "    batch_size              =   64                     ,\n",
        "    validation_split        =   0.2\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EhC1Mu2PEzAO",
        "outputId": "d2fdd6ab-d653-475e-ad07-d4c4c4a1440c"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 472ms/step - accuracy: 0.6799 - loss: 0.5656 - val_accuracy: 0.8474 - val_loss: 0.3597\n",
            "Epoch 2/3\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 472ms/step - accuracy: 0.8855 - loss: 0.2846 - val_accuracy: 0.8668 - val_loss: 0.3069\n",
            "Epoch 3/3\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 466ms/step - accuracy: 0.9337 - loss: 0.1824 - val_accuracy: 0.8666 - val_loss: 0.3781\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **OBSERVATIONS:**\n",
        "\n",
        "1.  The RNN Model has been trained with the help of the following parameters:-\n",
        "\n",
        "    (a.)   Training data ------->  X_train, Y_train\n",
        "\n",
        "    (b.)   epochs = 3 ---------> 3 iterations ae needed to train the model\n",
        "\n",
        "    (c.)   batch_size = 64 ----->  weights get updated after every 64 samples\n",
        "    \n",
        "    (d.)  validation_split = 0.2  ---->  20 % of the data is used fo validation.\n",
        "\n",
        "\n",
        "2.  After the model training, the accuracy of the model has increased while the loss function has reduced. So the model is working completely fine."
      ],
      "metadata": {
        "id": "nGgwmzH5FZaW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 7: Evaluate the RNN Model"
      ],
      "metadata": {
        "id": "SK7rJS9dF4EF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss, acc = model.evaluate(X_test, Y_test)\n",
        "\n",
        "print(f\"Test Accuracy: {acc:.4f}\")\n",
        "\n",
        "print(f\"Test Loss: {loss:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Blpsr5UnF6Eq",
        "outputId": "648b7dc7-80a3-41c8-9736-843539902214"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 98ms/step - accuracy: 0.8561 - loss: 0.3989\n",
            "Test Accuracy: 0.8584\n",
            "Test Loss: 0.3962\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**OBSERVATIONS:**\n",
        "\n",
        "1. After evaluating the RNN Model with the test data, it is known that  the test accuracy of the model is very high while the loss function is very less.\n",
        "\n",
        "2. So the model is completely fine."
      ],
      "metadata": {
        "id": "d44Ab2MWGBk-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 8: Make Predictions on Custom Text"
      ],
      "metadata": {
        "id": "h8uGIzCzGs8l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Get the index of each and every word\n",
        "\n",
        "word_index = imdb.get_word_index()\n",
        "\n",
        "### define the function to encode the words into integers\n",
        "def encoded_review(text):\n",
        "  ### get the tokens from the text\n",
        "  tokens = text.lower().split()\n",
        "  ### check if the token is present in the word index dic if not then assign with 2\n",
        "  encoded_text = [word_index.get(word,2) for word in tokens]\n",
        "  ### perform the padding on the encoded text to make all the input sequences as equal length\n",
        "  encoded_texts = pad_sequences([encoded_text],maxlen=max_len)\n",
        "  return(encoded_texts)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### define the sample text\n",
        "sample_text = \"This movie was amazing and the actors were brilliant\"\n",
        "\n",
        "\n",
        "res = encoded_review(sample_text)\n",
        "print(res)\n",
        "\n",
        "### Make the predictions from the encoded data\n",
        "predictions = model.predict(res)[0][0]\n",
        "print(predictions)\n",
        "\n",
        "\n",
        "if(predictions > 0.5):\n",
        "  print(\"Positive Review\")\n",
        "else:\n",
        "  print(\"Negative Review\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_GlmB5WaGu8v",
        "outputId": "c57fe3bb-2171-4373-9d14-8d747d3dc624"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0  11  17  13 477   2   1 153\n",
            "   68 527]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 224ms/step\n",
            "0.19938272\n",
            "Negative Review\n"
          ]
        }
      ]
    }
  ]
}