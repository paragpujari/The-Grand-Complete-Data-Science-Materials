{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Complete Python practical implementation of a Boltzmann Machine using a Restricted Boltzmann Machine (RBM)**\n",
        "\n",
        "### **Steps used in this Algorithm:-**\n",
        "\n",
        "1.  Import all the necessary Libraries\n",
        "\n",
        "2.  Load and Preprocess MNIST Dataset\n",
        "\n",
        "3.  Define RBM Model\n",
        "\n",
        "4.  Initialize Model\n",
        "\n",
        "5.  Train RBM (Contrastive Divergence - CD-1)\n",
        "\n",
        "6.  Visualize Reconstruction"
      ],
      "metadata": {
        "id": "m-JsjQLXWGla"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 1: Import all the necessary Libraries"
      ],
      "metadata": {
        "id": "HEnZ-0ptWkJZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "iYD-a-XsWmpQ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **OBSERVATIONS:**\n",
        "\n",
        "1.  torch is used for tensor operations and automatic differentiation.\n",
        "\n",
        "2.  nn helps define neural network parameters.\n",
        "\n",
        "3.  optim is used for optimization (SGD here).\n",
        "\n",
        "4.  torchvision is used to load MNIST dataset.\n",
        "\n",
        "5.  matplotlib is used for visualization."
      ],
      "metadata": {
        "id": "5fVx81FWXfIJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 2: Load and Preprocess MNIST Dataset"
      ],
      "metadata": {
        "id": "iuGds71DWr8b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform: convert to tensor and binarize\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Lambda(lambda x: (x > 0.5).float())\n",
        "])\n",
        "\n",
        "train_dataset = torchvision.datasets.MNIST(\n",
        "    root='./data',\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=transform\n",
        ")\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=64,\n",
        "    shuffle=True\n",
        ")\n"
      ],
      "metadata": {
        "id": "CLMSEB1VWt3Y"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **OBSERVATIONS:**\n",
        "\n",
        "1.  MNIST images are 28×28 grayscale images.\n",
        "\n",
        "2.  Pixel values are scaled between 0 and 1.\n",
        "\n",
        "3.  RBM works best on binary data, so we convert pixels:\n",
        "\n",
        "     (a.)  Values > 0.5 → 1\n",
        "\n",
        "     (b.)  Values ≤ 0.5 → 0"
      ],
      "metadata": {
        "id": "_ZhHa5CpXuGq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 3: Define RBM Model"
      ],
      "metadata": {
        "id": "fiC4ZMKdWz5Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RBM(nn.Module):\n",
        "    def __init__(self, visible_units=784, hidden_units=256):\n",
        "        super(RBM, self).__init__()\n",
        "\n",
        "        self.visible_units = visible_units\n",
        "        self.hidden_units = hidden_units\n",
        "\n",
        "        # Weight matrix\n",
        "        self.W = nn.Parameter(torch.randn(hidden_units, visible_units) * 0.01)\n",
        "\n",
        "        # Bias\n",
        "        self.h_bias = nn.Parameter(torch.zeros(hidden_units))\n",
        "        self.v_bias = nn.Parameter(torch.zeros(visible_units))\n",
        "\n",
        "    def sample_hidden(self, v):\n",
        "        prob = torch.sigmoid(torch.matmul(v, self.W.t()) + self.h_bias)\n",
        "        return prob, torch.bernoulli(prob)\n",
        "\n",
        "    def sample_visible(self, h):\n",
        "        prob = torch.sigmoid(torch.matmul(h, self.W) + self.v_bias)\n",
        "        return prob, torch.bernoulli(prob)\n",
        "\n",
        "    def forward(self, v):\n",
        "        # Positive phase\n",
        "        h_prob, h_sample = self.sample_hidden(v)\n",
        "\n",
        "        # Negative phase (reconstruction)\n",
        "        v_prob, v_sample = self.sample_visible(h_sample)\n",
        "        h_prob_neg, _ = self.sample_hidden(v_sample)\n",
        "\n",
        "        return v, v_sample, h_prob, h_prob_neg\n"
      ],
      "metadata": {
        "id": "RKllaIK0W2Kv"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 4: Initialize Model"
      ],
      "metadata": {
        "id": "lrUuweV9W5jr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "rbm = RBM().to(device)\n",
        "optimizer = optim.SGD(rbm.parameters(), lr=0.1)\n"
      ],
      "metadata": {
        "id": "abBsc6mcXBhq"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 5: Train RBM (Contrastive Divergence - CD-1)"
      ],
      "metadata": {
        "id": "kBZ4B5oBXGWI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 5\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    total_loss = 0\n",
        "\n",
        "    for data, _ in train_loader:\n",
        "        data = data.view(-1, 784).to(device)\n",
        "\n",
        "        v0 = data\n",
        "\n",
        "        # Forward pass\n",
        "        v, v_sample, h_prob, h_prob_neg = rbm(v0)\n",
        "\n",
        "        # Contrastive Divergence update\n",
        "        positive_grad = torch.matmul(h_prob.t(), v0)\n",
        "        negative_grad = torch.matmul(h_prob_neg.t(), v_sample)\n",
        "\n",
        "        rbm.W.grad = -(positive_grad - negative_grad) / v0.size(0)\n",
        "        rbm.v_bias.grad = -torch.mean(v0 - v_sample, dim=0)\n",
        "        rbm.h_bias.grad = -torch.mean(h_prob - h_prob_neg, dim=0)\n",
        "\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        loss = torch.mean((v0 - v_sample) ** 2)\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{epochs}], Loss: {total_loss/len(train_loader):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "otD5MsgTXIVB",
        "outputId": "8664c017-3672-4b08-8f64-6b8c98fbba45"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Loss: 0.0914\n",
            "Epoch [2/5], Loss: 0.0611\n",
            "Epoch [3/5], Loss: 0.0532\n",
            "Epoch [4/5], Loss: 0.0484\n",
            "Epoch [5/5], Loss: 0.0452\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **OBSERVATIONS:**\n",
        "\n",
        "The training loop implements Contrastive Divergence (CD-1) to train a Restricted Boltzmann Machine (RBM) in an unsupervised manner.\n",
        "\n",
        "  (1.)   Learning Nature\n",
        "\n",
        "   .       The model is trained without labels.\n",
        "   \n",
        "   .       It learns the probability distribution of input images.\n",
        "   \n",
        "   .       RBM is a generative, energy-based model.\n",
        "\n",
        "  (2.)   Training Mechanism\n",
        "\n",
        "  .        Each epoch consists of two main phases:\n",
        "\n",
        "    (a.)   Positive Phase (Data-driven)\n",
        "\n",
        "  .        The model computes hidden activations from real input data.\n",
        "\n",
        "  .        Strengthens connections that explain real patterns.\n",
        "\n",
        "  .        Encourages low energy for actual training samples.\n",
        "\n",
        "    (b.)   Negative Phase (Model-driven)\n",
        "\n",
        "  .        The model reconstructs input through Gibbs sampling.\n",
        "\n",
        "  .        Compares reconstructed data with original.\n",
        "\n",
        "  .        Weakens weights that produce unrealistic reconstructions.\n",
        "\n",
        "The difference between these two phases updates the weights.\n",
        "\n",
        "  (3.)   Contrastive Divergence (CD-1)\n",
        "\n",
        "  .        Only one reconstruction step is used.\n",
        "\n",
        "  .        Fast approximation of the true gradient.\n",
        "\n",
        "  .        Makes RBM training computationally feasible.\n",
        "\n",
        "  (4.)    Loss Behavior\n",
        "\n",
        "  .        Reconstruction error (MSE) is used to monitor training.\n",
        "\n",
        "  .        Loss gradually decreases across epochs.\n",
        "\n",
        "  .        Indicates improved reconstruction ability.\n",
        "\n",
        "  (5.)    Feature Learning\n",
        "\n",
        "  .       Hidden units automatically learn meaningful features:\n",
        "\n",
        "        .         Edges\n",
        "\n",
        "        .         Curves\n",
        "\n",
        "        .         Digit strokes\n",
        "\n",
        "Each hidden neuron becomes a feature detector.\n",
        "\n",
        "  (6.)   Energy Minimization\n",
        "\n",
        "   .     The model adjusts parameters so that:\n",
        "\n",
        "        .     Real data → Low energy\n",
        "\n",
        "        .    Random/noisy patterns → High energy\n",
        "\n",
        "This shapes the energy landscape over training.\n",
        "\n",
        "  (7.)   Overall Outcome\n",
        "\n",
        "After multiple epochs:\n",
        "\n",
        "      .      Reconstruction quality improves.\n",
        "\n",
        "      .      Model captures underlying structure of MNIST digits.\n",
        "\n",
        "      .      RBM successfully models data distribution."
      ],
      "metadata": {
        "id": "1MA8-jb3YinT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 6:  Visualize Reconstruction"
      ],
      "metadata": {
        "id": "_E37M6KpXOIy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get one batch\n",
        "data_iter = iter(train_loader)\n",
        "images, _ = next(data_iter)\n",
        "\n",
        "images = images.view(-1, 784).to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    _, reconstructed, _, _ = rbm(images)\n",
        "\n",
        "# Plot original and reconstructed\n",
        "plt.figure(figsize=(10,4))\n",
        "\n",
        "for i in range(5):\n",
        "    # Original\n",
        "    plt.subplot(2,5,i+1)\n",
        "    plt.imshow(images[i].view(28,28).cpu(), cmap='gray')\n",
        "    plt.axis('off')\n",
        "\n",
        "    # Reconstructed\n",
        "    plt.subplot(2,5,i+6)\n",
        "    plt.imshow(reconstructed[i].view(28,28).cpu(), cmap='gray')\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "id": "50af1jvAXRJv",
        "outputId": "b83084f5-4381-4e3b-8320-65bf098e6666"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x400 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **OBSERVATIONS:**\n",
        "\n",
        "You will see:\n",
        "\n",
        "1.   Top row → Original images\n",
        "\n",
        "2.   Bottom row → Reconstructed images\n",
        "\n",
        "3.   Early epochs:\n",
        "\n",
        "    .     Blurry reconstructions.\n",
        "\n",
        "4.   After few epochs:\n",
        "\n",
        "    .     Digits become recognizable.\n",
        "\n",
        "5.   This proves the RBM learned latent features."
      ],
      "metadata": {
        "id": "KLjYQo8lYEQA"
      }
    }
  ]
}