{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d8e50ce",
   "metadata": {},
   "source": [
    "### Count Vectorizer vs Tfidf Vectorizer\n",
    "\n",
    "1.  Both the Count Vectorizer and Tfidf Vectorizer are the text representation techniques that is used to convert the text into the numerical array vectors taht can be Numerical Array vectors that can be easily be trained by the Machine Learning Model.\n",
    "\n",
    "\n",
    "### Definition :-\n",
    "\n",
    "1.  Count Vectorizer ------->  converts the text into the matrix of word counts.\n",
    "\n",
    "2.  Tfidf Vectorizer ------->  converts the text into the Tfidf scores.\n",
    "\n",
    "### Steps used in this Algorithm:---\n",
    "\n",
    "1.   Import all the necessary Libraries\n",
    "\n",
    "2.   Create Sample Corpus\n",
    "\n",
    "3.   Apply CountVectorizer (Bag of Words)\n",
    "\n",
    "4.   Apply TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0600206d",
   "metadata": {},
   "source": [
    "### Step 1: Import all the necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8840445a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import  numpy             as  np\n",
    "import  pandas            as  pd\n",
    "import  matplotlib.pyplot as plt\n",
    "import  seaborn           as sns\n",
    "\n",
    "from    sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ad4e22",
   "metadata": {},
   "source": [
    "### OBSERVATIONS:\n",
    "\n",
    "1.  numpy ------------->   Computation of numerical array\n",
    "\n",
    "2.  pandas ------------>   Data Creation and Manipulation\n",
    "\n",
    "3.  matplotlib -------->   Data Visualization\n",
    "\n",
    "4.  seaborn   --------->   Data Correlation\n",
    "\n",
    "5.  CountVectorizer ---->  Converts the text into the matrix of word counts\n",
    "\n",
    "6.  TfidfVectorizer -----> Vonverts the text into the matrix of Tfidf scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7e3993",
   "metadata": {},
   "source": [
    "### Step 2:  Create Sample Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1fcb2a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a small collection of text documents\n",
    "corpus = [\n",
    "    \"I love data science\",\n",
    "    \"Data science is amazing\",\n",
    "    \"I love machine learning\",\n",
    "    \"Machine learning and data science are related\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79351e1",
   "metadata": {},
   "source": [
    "### OBSERVATIONS:\n",
    "\n",
    "1.  corpus â†’ A list of documents (sentences).\n",
    "\n",
    "2.  Each sentence will be converted into numerical features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422433f5",
   "metadata": {},
   "source": [
    "### Step 3: Apply CountVectorizer (Bag of Words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2b7a9956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Compressed Sparse Row sparse matrix of dtype 'int64'\n",
      "\twith 17 stored elements and shape (4, 10)>\n",
      "  Coords\tValues\n",
      "  (0, 6)\t1\n",
      "  (0, 3)\t1\n",
      "  (0, 9)\t1\n",
      "  (1, 3)\t1\n",
      "  (1, 9)\t1\n",
      "  (1, 4)\t1\n",
      "  (1, 0)\t1\n",
      "  (2, 6)\t1\n",
      "  (2, 7)\t1\n",
      "  (2, 5)\t1\n",
      "  (3, 3)\t1\n",
      "  (3, 9)\t1\n",
      "  (3, 7)\t1\n",
      "  (3, 5)\t1\n",
      "  (3, 1)\t1\n",
      "  (3, 2)\t1\n",
      "  (3, 8)\t1\n"
     ]
    }
   ],
   "source": [
    "### Create the object for Bag of Words Model\n",
    "\n",
    "count = CountVectorizer()\n",
    "\n",
    "### Fit and transform the corpus text\n",
    "X = count.fit_transform(corpus)\n",
    "\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6590701b",
   "metadata": {},
   "source": [
    "### OBSERVATIONS:\n",
    "\n",
    "1. The object for the Bag Of Model is created.\n",
    "\n",
    "2. Using the bag of model object, we have transformed the corpus text into the matrix of word counts.\n",
    "\n",
    "3. It has maximum of non-zero values.\n",
    "\n",
    "4. It needs to be converted into the numpy array for better view and visibility\n",
    "\n",
    "5. It helps in tokenizing, removing the punctuations and building the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "799593d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 1 0 0 1 0 0 1]\n",
      " [1 0 0 1 1 0 0 0 0 1]\n",
      " [0 0 0 0 0 1 1 1 0 0]\n",
      " [0 1 1 1 0 1 0 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "### Convert the matrix of word count into numpy array for better view\n",
    "\n",
    "X = X.toarray()\n",
    "\n",
    "\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458c771c",
   "metadata": {},
   "source": [
    "### OBSERVATIONS:\n",
    "\n",
    "1. The sparse matrix is converted into the numpy array for better view and visibility.\n",
    "\n",
    "2. This numpy array can be easily be trained in any model as an input.\n",
    "\n",
    "3. every row represents every sentence in the corpus and the words mentioned in each corpus text is marked as '1' as the rest is marked as '0'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee8b522",
   "metadata": {},
   "source": [
    "### Step 4;  Apply TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5a92404f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
      "\twith 17 stored elements and shape (4, 10)>\n",
      "  Coords\tValues\n",
      "  (0, 6)\t0.6578293132998527\n",
      "  (0, 3)\t0.5325695234255544\n",
      "  (0, 9)\t0.5325695234255544\n",
      "  (1, 3)\t0.38044393252779135\n",
      "  (1, 9)\t0.38044393252779135\n",
      "  (1, 4)\t0.5960389368177127\n",
      "  (1, 0)\t0.5960389368177127\n",
      "  (2, 6)\t0.5773502691896257\n",
      "  (2, 7)\t0.5773502691896257\n",
      "  (2, 5)\t0.5773502691896257\n",
      "  (3, 3)\t0.28380912750743487\n",
      "  (3, 9)\t0.28380912750743487\n",
      "  (3, 7)\t0.35056073478553806\n",
      "  (3, 5)\t0.35056073478553806\n",
      "  (3, 1)\t0.4446418411636436\n",
      "  (3, 2)\t0.4446418411636436\n",
      "  (3, 8)\t0.4446418411636436\n"
     ]
    }
   ],
   "source": [
    "### Create the object for Tfidfvectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "\n",
    "### using the object for tfidf vectorizer , transform the text\n",
    "\n",
    "X = tfidf.fit_transform(corpus)\n",
    "\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5942c8",
   "metadata": {},
   "source": [
    "### OBSERVATIONS:\n",
    "\n",
    "1. The object for Tfidf Vectprizer is created.\n",
    "\n",
    "2. It depicts \n",
    "\n",
    "     (a.)  how many times a particular term appears in the document\n",
    "\n",
    "     (b.)  how unique a term appears across the entire corpus text\n",
    "\n",
    "3. It converts the corpus text into the matrix of Tfidf scores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c80a24",
   "metadata": {},
   "source": [
    "### Which is more important ?\n",
    "\n",
    "1.  Tfidf Vectorizer is more important than the Count Vectorizer. (Advantages of Tfidf Vectorizer) This is because of the following reasons:---\n",
    "\n",
    "    (a.)   It can handle the common words in a better way\n",
    "\n",
    "    (b.)   better handles the classification tasks\n",
    "\n",
    "    (c.)   reduces the noise\n",
    "\n",
    "\n",
    "3. The main disadvantages of Count Vectorizer is :-----\n",
    "\n",
    "   (a.)   Frequency is a problem in which a word occuring more than once.\n",
    "\n",
    "   (b.)   It cannot handle the deep learning models\n",
    "\n",
    "   (c.)   It cannot word with the large datasets"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vens",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
