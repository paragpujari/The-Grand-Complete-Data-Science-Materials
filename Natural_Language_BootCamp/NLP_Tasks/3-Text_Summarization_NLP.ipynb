{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e98d26c2",
   "metadata": {},
   "source": [
    "### Text Summarization\n",
    "\n",
    "Text Summarization refers to the process of extracting all the imporatnt essence from the combined input text and give a precise summary and idea about the complete text.\n",
    "\n",
    "\n",
    "### Steps used in this Algorithm:----\n",
    "\n",
    "1.  Import all the necessary libraries\n",
    "\n",
    "2.  Download the required NLTK Data\n",
    "\n",
    "3.  Define the  Input Text\n",
    "\n",
    "4.  Convert the Text into Sentences\n",
    "\n",
    "5.  Perform Text-Preprocessing on the particular text\n",
    "\n",
    "6.  Convert the Sentences to TF-IDF Matrix\n",
    "\n",
    "7.  Calculate the Sentence Scores\n",
    "\n",
    "8.  Select the Top Sentences\n",
    "\n",
    "9.  Generate the Final Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0e3af2",
   "metadata": {},
   "source": [
    "### Step 1: Import all the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1466,
   "id": "5791a888",
   "metadata": {},
   "outputs": [],
   "source": [
    "import    numpy                as      np\n",
    "import    pandas               as      pd\n",
    "import    matplotlib.pyplot    as      plt\n",
    "import    seaborn              as      sns\n",
    "\n",
    "import    nltk\n",
    "\n",
    "from      nltk.tokenize                     import  sent_tokenize, RegexpTokenizer, word_tokenize\n",
    "from      nltk.corpus                       import  stopwords\n",
    "\n",
    "from      sklearn.feature_extraction.text   import TfidfVectorizer\n",
    "\n",
    "from      sklearn.model_selection           import train_test_split\n",
    "from      sklearn.preprocessing             import StandardScaler\n",
    "from      sklearn.metrics                   import accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8cdb81a",
   "metadata": {},
   "source": [
    "### OBSERVATIONS:\n",
    "\n",
    "1.  numpy --------------->  Computation of numerical  array\n",
    "\n",
    "2.  pandas -------------->  Data Manipulation\n",
    "\n",
    "3.  matplotlib ---------->  Data Visualization\n",
    "\n",
    "4.  seaborn ------------->  Data Correlation\n",
    "\n",
    "5.  nltk ---------------->  NLP Library used for text preprocessing\n",
    "\n",
    "6.  sent_tokenize --------> breaks the paragraphs into sentences\n",
    "\n",
    "7.  RegexpTokenizer ------> normalizes and removes all the punctuations from the text\n",
    "\n",
    "8.  corpus ---------------> A container that has two or more sentences\n",
    "\n",
    "9.  stopwords ------------> words with no meaning\n",
    "\n",
    "10. TfidfVectorizer -------> converts the text into Tf-idf sparse/ vectors\n",
    "\n",
    "11.  train_test_split -----> divides the data into training and testing data\n",
    "\n",
    "12.  StandardScaler -------> scales all the data in one range from 0 to 1\n",
    "\n",
    "13.  metrics --------------> evaluates the performance of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b491e5f",
   "metadata": {},
   "source": [
    "### Step 2:  Download the required NLTK Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1467,
   "id": "32cbf8cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Error loading average_perceptron_tagger_eng: Package\n",
      "[nltk_data]     'average_perceptron_tagger_eng' not found in index\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1467,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt_tab')\n",
    "nltk.download('average_perceptron_tagger_eng')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05999cb",
   "metadata": {},
   "source": [
    "### OBSERVATIONS:\n",
    "\n",
    "1.  punkt_tab                     -------------->  Tokenization model\n",
    "\n",
    "2.  average_perceptron_tagger_eng -------------->  POS Tagging Model\n",
    "\n",
    "3.  stopwords                     -------------->  Stop words model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e852486",
   "metadata": {},
   "source": [
    "### Step 3:  Define the  Input Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1468,
   "id": "84ad8eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "Artificial Intelligence is transforming industries worldwide.\n",
    "Machine learning is a subset of AI that enables systems to learn from data.\n",
    "Deep learning is a specialized form of machine learning using neural networks.\n",
    "AI is widely used in healthcare, finance, and transportation.\n",
    "Companies are investing heavily in AI research and development.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1469,
   "id": "76194fae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nArtificial Intelligence is transforming industries worldwide.\\nMachine learning is a subset of AI that enables systems to learn from data.\\nDeep learning is a specialized form of machine learning using neural networks.\\nAI is widely used in healthcare, finance, and transportation.\\nCompanies are investing heavily in AI research and development.\\n'"
      ]
     },
     "execution_count": 1469,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a906b17",
   "metadata": {},
   "source": [
    "### Step 4: Convert the Text into Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1470,
   "id": "4bc9eadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from  nltk.tokenize  import  sent_tokenize\n",
    "\n",
    "### perform the sentence tokenization on the texts\n",
    "\n",
    "sentences = sent_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1471,
   "id": "1b50ea43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\nArtificial Intelligence is transforming industries worldwide.',\n",
       " 'Machine learning is a subset of AI that enables systems to learn from data.',\n",
       " 'Deep learning is a specialized form of machine learning using neural networks.',\n",
       " 'AI is widely used in healthcare, finance, and transportation.',\n",
       " 'Companies are investing heavily in AI research and development.']"
      ]
     },
     "execution_count": 1471,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d90964d",
   "metadata": {},
   "source": [
    "### OBSERVATIONS:\n",
    "\n",
    "1. Here the text is converted into the sentences using sent_tokenize.\n",
    "\n",
    "2. Each and every sentence is trated seperately."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2452259e",
   "metadata": {},
   "source": [
    "### Step 5: Perform Text-Preprocessing on the particular text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1472,
   "id": "7944f4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Convert the sentences in list to string\n",
    "\n",
    "sentences = \" \".join(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1473,
   "id": "4401835a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nArtificial Intelligence is transforming industries worldwide. Machine learning is a subset of AI that enables systems to learn from data. Deep learning is a specialized form of machine learning using neural networks. AI is widely used in healthcare, finance, and transportation. Companies are investing heavily in AI research and development.'"
      ]
     },
     "execution_count": 1473,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1474,
   "id": "96609423",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Remove all the punctuations from the text\n",
    "\n",
    "import re\n",
    "\n",
    "cleaned_text = re.sub(r'[\\n]','',sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1475,
   "id": "4f1110dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Artificial Intelligence is transforming industries worldwide. Machine learning is a subset of AI that enables systems to learn from data. Deep learning is a specialized form of machine learning using neural networks. AI is widely used in healthcare, finance, and transportation. Companies are investing heavily in AI research and development.'"
      ]
     },
     "execution_count": 1475,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1476,
   "id": "1a88f756",
   "metadata": {},
   "outputs": [],
   "source": [
    "### perform the word tokenization on the sentences\n",
    "\n",
    "words = word_tokenize(cleaned_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1477,
   "id": "bf93518b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Artificial',\n",
       " 'Intelligence',\n",
       " 'is',\n",
       " 'transforming',\n",
       " 'industries',\n",
       " 'worldwide',\n",
       " '.',\n",
       " 'Machine',\n",
       " 'learning',\n",
       " 'is',\n",
       " 'a',\n",
       " 'subset',\n",
       " 'of',\n",
       " 'AI',\n",
       " 'that',\n",
       " 'enables',\n",
       " 'systems',\n",
       " 'to',\n",
       " 'learn',\n",
       " 'from',\n",
       " 'data',\n",
       " '.',\n",
       " 'Deep',\n",
       " 'learning',\n",
       " 'is',\n",
       " 'a',\n",
       " 'specialized',\n",
       " 'form',\n",
       " 'of',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'using',\n",
       " 'neural',\n",
       " 'networks',\n",
       " '.',\n",
       " 'AI',\n",
       " 'is',\n",
       " 'widely',\n",
       " 'used',\n",
       " 'in',\n",
       " 'healthcare',\n",
       " ',',\n",
       " 'finance',\n",
       " ',',\n",
       " 'and',\n",
       " 'transportation',\n",
       " '.',\n",
       " 'Companies',\n",
       " 'are',\n",
       " 'investing',\n",
       " 'heavily',\n",
       " 'in',\n",
       " 'AI',\n",
       " 'research',\n",
       " 'and',\n",
       " 'development',\n",
       " '.']"
      ]
     },
     "execution_count": 1477,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1478,
   "id": "e99252f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Artificial', 'Intelligence', 'transforming', 'industries', 'worldwide', '.', 'Machine', 'learning', 'subset', 'AI', 'enables', 'systems', 'learn', 'data', '.', 'Deep', 'learning', 'specialized', 'form', 'machine', 'learning', 'using', 'neural', 'networks', '.', 'AI', 'widely', 'used', 'healthcare', ',', 'finance', ',', 'transportation', '.', 'Companies', 'investing', 'heavily', 'AI', 'research', 'development', '.']\n"
     ]
    }
   ],
   "source": [
    "### define all the english stop words\n",
    "\n",
    "from nltk.corpus  import stopwords\n",
    "\n",
    "english_stopwords = stopwords.words(\"english\")\n",
    "\n",
    "#print(english_stopwords)\n",
    "\n",
    "\n",
    "### Remove all the filtered words from the text\n",
    "\n",
    "res = [x for x in words if(x not in english_stopwords)]\n",
    "\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1479,
   "id": "0f02367b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### convert the filtered words to string\n",
    "\n",
    "res = \" \".join(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1480,
   "id": "8e31a520",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Artificial Intelligence transforming industries worldwide . Machine learning subset AI enables systems learn data . Deep learning specialized form machine learning using neural networks . AI widely used healthcare , finance , transportation . Companies investing heavily AI research development .'"
      ]
     },
     "execution_count": 1480,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1481,
   "id": "98cd1e00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Artificial Intelligence transforming industries worldwide ', ' Machine learning subset AI enables systems learn data ', ' Deep learning specialized form machine learning using neural networks ', ' AI widely used healthcare , finance , transportation ', ' Companies investing heavily AI research development ', '']\n"
     ]
    }
   ],
   "source": [
    "### convert the filtered words in string to list of sentences\n",
    "\n",
    "results = res.split(\".\")\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35802247",
   "metadata": {},
   "source": [
    "### OBSERVATIONS:\n",
    "\n",
    "1. The sentence text is entered as the input string.\n",
    "\n",
    "2. The symbol '\\n' is removed using regular expression.\n",
    "\n",
    "3. Word tokenization is performed on the sentences to get it converted into words.\n",
    "\n",
    "4. All the english stopwords are defined and these stopwords are removed from the input text.\n",
    "\n",
    "5. Then the filtered words are converted from list to strings.\n",
    "\n",
    "6. These filtered words in string is converted into the list of strings using split funtion.\n",
    "\n",
    "7. Then the output is the list of the sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d5a601",
   "metadata": {},
   "source": [
    "### Step 6:  Convert the Sentences to TF-IDF Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1482,
   "id": "8749b41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create a object for Tf-idf Vectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "\n",
    "### using the object of tfidf vectorizer, transform the input text\n",
    "\n",
    "input_sparse_matrix = tfidf.fit_transform(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1483,
   "id": "bc95ee47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
       "\twith 33 stored elements and shape (6, 29)>"
      ]
     },
     "execution_count": 1483,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sparse_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a9949f",
   "metadata": {},
   "source": [
    "### OBSERVATIONS:\n",
    "\n",
    "1.  Here a sparse matrix is created thst has a maximum of non-zeros values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1484,
   "id": "ebf50823",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Now convert the sparse matrix to numpy array for better view\n",
    "\n",
    "X = input_sparse_matrix.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1485,
   "id": "2b7d23a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.4472136 , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.4472136 , 0.4472136 , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.4472136 , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.4472136 ],\n",
       "       [0.26501964, 0.        , 0.        , 0.38280352, 0.        ,\n",
       "        0.        , 0.38280352, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.38280352,\n",
       "        0.31390437, 0.31390437, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.38280352, 0.38280352, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.32682326,\n",
       "        0.        , 0.        , 0.        , 0.32682326, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.5359995 , 0.26799975, 0.32682326, 0.32682326, 0.        ,\n",
       "        0.32682326, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.32682326, 0.        , 0.        ],\n",
       "       [0.29576019, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.42720625, 0.        , 0.42720625,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.42720625,\n",
       "        0.42720625, 0.        , 0.42720625, 0.        ],\n",
       "       [0.29576019, 0.        , 0.42720625, 0.        , 0.        ,\n",
       "        0.42720625, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.42720625, 0.        , 0.        , 0.42720625, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.42720625,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 1485,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a84a49",
   "metadata": {},
   "source": [
    "### OBSERVATIONS:\n",
    "\n",
    "1. The sparse matrix input is converted into numpy array.\n",
    "\n",
    "2. fit_transform(text)  ---->  learns all the vocabularies from the filtered text and builds the matrix of tf-idf scores\n",
    "\n",
    "3. We have obtained the scores of tf-idf matrix where all the common words have been marked as 0 and all the important words have been marked greater than 0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dec7324",
   "metadata": {},
   "source": [
    "### Step 7: Calculate the Sentence Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1486,
   "id": "808119b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_scores = np.sum(X,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1487,
   "id": "17a47a7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.23606798, 2.80684599, 2.76493883, 2.43179145, 2.43179145,\n",
       "       0.        ])"
      ]
     },
     "execution_count": 1487,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5911ef8",
   "metadata": {},
   "source": [
    "### OBSERVATIONS:\n",
    "\n",
    "1. We have obtained the sum of all the tfidf scores for each and every sentence.\n",
    "\n",
    "2. The sentence having the highest Tf-idf score is considered to be the most important."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757635d1",
   "metadata": {},
   "source": [
    "### Step 8: Select the Top Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1488,
   "id": "182126a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### extract the top 2 most important sentences\n",
    "\n",
    "topn = 1\n",
    "ans = sentences_scores.argsort()[::-topn]\n",
    "x = ans[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1489,
   "id": "2287cefd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2]\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837f1a21",
   "metadata": {},
   "source": [
    "### OBSERVATIONS:\n",
    "\n",
    "1. The sentences present at index 1 and index 2 are the top 2 most important sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a55cd8",
   "metadata": {},
   "source": [
    "### Step 9:  Generate the Final Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1490,
   "id": "8acee4f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nArtificial Intelligence is transforming industries worldwide. Machine learning is a subset of AI that enables systems to learn from data. Deep learning is a specialized form of machine learning using neural networks. AI is widely used in healthcare, finance, and transportation. Companies are investing heavily in AI research and development.'"
      ]
     },
     "execution_count": 1490,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1491,
   "id": "1a0e7379",
   "metadata": {},
   "outputs": [],
   "source": [
    "### convert the sentences in strings to list\n",
    "\n",
    "sentences = sentences.split(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1492,
   "id": "4087d3c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\nArtificial Intelligence is transforming industries worldwide',\n",
       " ' Machine learning is a subset of AI that enables systems to learn from data',\n",
       " ' Deep learning is a specialized form of machine learning using neural networks',\n",
       " ' AI is widely used in healthcare, finance, and transportation',\n",
       " ' Companies are investing heavily in AI research and development',\n",
       " '']"
      ]
     },
     "execution_count": 1492,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1493,
   "id": "19091d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Extract the top2 most imporant sentences and generate the final summary\n",
    "\n",
    "res = [sentences[i] for i in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1494,
   "id": "f69c40ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' Machine learning is a subset of AI that enables systems to learn from data',\n",
       " ' Deep learning is a specialized form of machine learning using neural networks']"
      ]
     },
     "execution_count": 1494,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vens",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
