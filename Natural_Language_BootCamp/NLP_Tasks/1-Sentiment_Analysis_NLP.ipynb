{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74698405",
   "metadata": {},
   "source": [
    "### Aim:---\n",
    "\n",
    "1.  To perform an end to end sentimental analysis implementation on an imdb movie review dataset and predict whether the review is positive or negative.\n",
    "\n",
    "\n",
    "### Steps used in this Algorithm :----\n",
    "\n",
    "1.  Import all the necessary Libraries\n",
    "\n",
    "2.  Download the necessary NLTK libraries\n",
    "\n",
    "3.  Create the Sample Dataset\n",
    "\n",
    "4.  Perform the Text Preprocessing Function\n",
    "\n",
    "5.  Apply Cleaning\n",
    "\n",
    "6.  Convert Text to Numerical Form (TF-IDF)\n",
    "\n",
    "7.  Divide the dataset into independent and dependent variables\n",
    "\n",
    "8.  Train-Test Split\n",
    "\n",
    "9.  Train Logistic Regression Model\n",
    "\n",
    "10. Make Predictions\n",
    "\n",
    "11. Evaluate the Model\n",
    "\n",
    "12. Predict on New Review"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d6f183",
   "metadata": {},
   "source": [
    "### Step 1: Import all the necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "id": "614fc585",
   "metadata": {},
   "outputs": [],
   "source": [
    "import  numpy               as   np\n",
    "import  pandas              as   pd\n",
    "import  matplotlib.pyplot   as   plt\n",
    "import  seaborn             as   sns\n",
    "\n",
    "import  nltk\n",
    "\n",
    "from    nltk.tokenize   import  RegexpTokenizer, word_tokenize\n",
    "from    nltk.corpus     import  stopwords\n",
    "\n",
    "from    sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from    sklearn.model_selection         import train_test_split\n",
    "from    sklearn.preprocessing           import StandardScaler\n",
    "from    sklearn.linear_model            import LogisticRegression\n",
    "from    sklearn.metrics                 import accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d97b2c6",
   "metadata": {},
   "source": [
    "### OBSERVATIONS:\n",
    "\n",
    "1.  numpy  ------------------>  Computation of the numerical array\n",
    "\n",
    "2.  pandas ------------------>  Data Cleaning and Manipulation\n",
    "\n",
    "3.  matplotlib -------------->  Data Visualization\n",
    "\n",
    "4.  seaborn   --------------->  Data Correlation\n",
    "\n",
    "5.  nltk -------------------->  Contains all the library for text preprocessing\n",
    "\n",
    "6.  tokenize ---------------->  breaks the text into sub parts\n",
    "\n",
    "7.  word_tokenize ----------->  breaks the text into words\n",
    "\n",
    "8.  corpus ------------------>  contains a series of text\n",
    "\n",
    "9.  stopwords --------------->  words having no meaning\n",
    "\n",
    "10. feature_extraction ------>  extracting all the essential information from the features\n",
    "\n",
    "11. TfidfVectorizer  -------->  converts the text into Tfidf score matrix\n",
    "\n",
    "12. train_test_split -------->  split the data into training and testing data\n",
    "\n",
    "13. StandardScaler ---------->  sclaes the data in one range between 0 to 1\n",
    "\n",
    "14. LogisticRegression ------>  provides the result in 1 or 0 in a binary classification problem\n",
    "\n",
    "15. RegexpTokenizer ----------> Tokenizing the Regular expression statement\n",
    "\n",
    "16. metrics ------------------> evaluate the performance of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba26bb12",
   "metadata": {},
   "source": [
    "### Step 2: Download the necessary NLTK libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "id": "e9b077d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Error loading average_perceptron_tagger_eng: Package\n",
      "[nltk_data]     'average_perceptron_tagger_eng' not found in index\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 486,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('average_perceptron_tagger_eng')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0d60ca",
   "metadata": {},
   "source": [
    "### OBSERVATIONS:\n",
    "\n",
    "1.  punkt_tab --------------->   It represents the tokenization model\n",
    "\n",
    "2.  average_perceptron_tagger_eng ------> It represents the POS Tagging Model\n",
    "\n",
    "3.  stopwords         -------------------> It represents the model for stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1991218",
   "metadata": {},
   "source": [
    "### Step 3:  Create the Sample Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "id": "7f5f7f53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     review  sentiment\n",
      "0       I love this product, it is amazing!          1\n",
      "1  Worst experience ever, very bad service.          0\n",
      "2             Absolutely fantastic quality.          1\n",
      "3         I hate this item, waste of money.          0\n",
      "4             Very happy with the purchase.          1\n",
      "5         Terrible, I will never buy again.          0\n"
     ]
    }
   ],
   "source": [
    "data = {\n",
    "    \"review\": [\n",
    "        \"I love this product, it is amazing!\",\n",
    "        \"Worst experience ever, very bad service.\",\n",
    "        \"Absolutely fantastic quality.\",\n",
    "        \"I hate this item, waste of money.\",\n",
    "        \"Very happy with the purchase.\",\n",
    "        \"Terrible, I will never buy again.\"\n",
    "    ],\n",
    "    \"sentiment\": [1, 0, 1, 0, 1, 0]  # 1 = Positive, 0 = Negative\n",
    "}\n",
    "\n",
    "\n",
    "### Construct the DataFrame from the above data\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32252474",
   "metadata": {},
   "source": [
    "### OBSERVATIONS:\n",
    "\n",
    "1. The dataset is constructed.\n",
    "\n",
    "2. It has two columns. One is review and the other is label.\n",
    "\n",
    "3. The input column represents the text review.\n",
    "\n",
    "4. The output column represents the label.\n",
    "\n",
    "5. The review text is string in nature. So we need to convert it into the numerical foem so that it can be easily be trained by the machine learning model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77105cbb",
   "metadata": {},
   "source": [
    "### Step 4: Perform the Text Preprocessing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "id": "cf6a8b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = RegexpTokenizer(r'\\w+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "id": "ecd31d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "### define the function\n",
    "def clean_text(text):\n",
    "    ### convert the text into the lower case\n",
    "    text = text.lower()\n",
    "    ### perform the Regular expression tokenization on the text to remove all the punctuationa and special symbols\n",
    "    text = reg.tokenize(text)\n",
    "    ### convert the text in lists to words\n",
    "    text = \" \".join(text)\n",
    "    ### perform the word tokenization on the text\n",
    "    words = word_tokenize(text)\n",
    "\n",
    "    ### define the english stopwords\n",
    "    english_stopwords = stopwords.words(\"english\")\n",
    "\n",
    "    ### filter out all the stopwords from each text\n",
    "    res = [x for x in words if(x not in english_stopwords)]\n",
    "\n",
    "    ### convert all the words from list to words\n",
    "    res = \" \".join(res)\n",
    "\n",
    "\n",
    "    return(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f59036",
   "metadata": {},
   "source": [
    "### OBSERVATIONS:\n",
    "\n",
    "1. The \"clean_text\" function is defined.\n",
    "\n",
    "2. First each input text is accepted as an input.\n",
    "\n",
    "3. This input text is first converted into lower case.\n",
    "\n",
    "4. Then regular expression is applied on each and every text to remove all the punctuations and special symbols from the text.\n",
    "\n",
    "5. The regularized words in list is again converted into words.\n",
    "\n",
    "6. Then the word tokenization is applied on the regularized words to convert each text into words.\n",
    "\n",
    "7. All the stopwords of english data is defined.\n",
    "\n",
    "8. Then all the english stopwords are removed from the tokenized words to get a fileterd text data.\n",
    "\n",
    "9. The fileterd text data in list is converted back into the words."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c313f4",
   "metadata": {},
   "source": [
    "### Step 5:  Apply Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "id": "7a843a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "### call the function\n",
    "df['clean_review'] = df['review'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "id": "4b4a6f50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                 love product amazing\n",
       "1    worst experience ever bad service\n",
       "2         absolutely fantastic quality\n",
       "3                hate item waste money\n",
       "4                       happy purchase\n",
       "5                   terrible never buy\n",
       "Name: clean_review, dtype: object"
      ]
     },
     "execution_count": 491,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['clean_review']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9208b8",
   "metadata": {},
   "source": [
    "### OBSERVATIONS:\n",
    "\n",
    "1. The function 'clean_text' is called where the text preprocessing is applied to each and every row of the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f646e0",
   "metadata": {},
   "source": [
    "### Step 6: Convert Text to Numerical Form (TF-IDF)\n",
    "\n",
    "Q.>  Why Tfidf Vectoization is used in Logistic Regression ?\n",
    "\n",
    "Ans:>\n",
    "\n",
    "1.   Logistic Regression can easily work with the high dimensional data and sparse matrix.\n",
    "\n",
    "     After applying Tfidf vectorizer on the text, the text becomes high dimendional sparse data.\n",
    "\n",
    "     So here Tfidf vectorizer can easily be used in Logistic Regression.\n",
    "\n",
    "\n",
    "2.  Logistic Regression is a linear model.\n",
    "\n",
    "    Tfidf vectorizer produces the output in the form of the numerical data. The most important words have been assigned with the higher weights and the common words have been given lower weights, so as to reduce its imprtance.\n",
    "\n",
    "\n",
    "3. Tfidf Vectorizer reduces the noise. It is used in Logistic Regression so as to reduce the influence of common words.\n",
    "\n",
    "\n",
    "4.  Logistic Regression works well with L2-regularized data.\n",
    "\n",
    "    Tfidf Vectorizer even produces normalized results so as to improve the generalization of the model.\n",
    "\n",
    "    So Tfidf Vectorizer is used in Logistic Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "id": "d4cf0e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from    sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "### Create an object for Tfidf Vectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(\n",
    "    ngram_range=(1,2),      # Use unigrams + bigrams\n",
    "    min_df=1,\n",
    "    max_df=0.9\n",
    ")\n",
    "\n",
    "### using the object of tfidf, transform the inputs\n",
    "\n",
    "X_tfidf = tfidf.fit_transform(df['clean_review'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "id": "18db0d5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
       "\twith 34 stored elements and shape (6, 34)>"
      ]
     },
     "execution_count": 493,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "id": "49dbe69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### convert to numpy array for better view and visibility\n",
    "\n",
    "X_vectorized = X_tfidf.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "id": "91411a4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.4472136 , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.4472136 , 0.4472136 ,\n",
       "        0.        , 0.        , 0.        , 0.4472136 , 0.4472136 ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.33333333, 0.33333333,\n",
       "        0.        , 0.33333333, 0.33333333, 0.33333333, 0.33333333,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.33333333, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.33333333, 0.33333333],\n",
       "       [0.4472136 , 0.4472136 , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.4472136 , 0.4472136 , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.4472136 , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.37796447,\n",
       "        0.37796447, 0.37796447, 0.37796447, 0.        , 0.        ,\n",
       "        0.37796447, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.37796447, 0.37796447, 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.57735027, 0.57735027, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.57735027, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.4472136 , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.4472136 , 0.4472136 , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.4472136 , 0.4472136 ,\n",
       "        0.        , 0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 495,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_vectorized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70fd8d70",
   "metadata": {},
   "source": [
    "### OBSERVATIONS:\n",
    "\n",
    "1.  We have the input in the form of 'clean_review'.\n",
    "\n",
    "2.  Then tfidf vectorizer is applied on the clean_review to produce the sparse matrix of tfidf scores\n",
    "\n",
    "3.  Then this sparse matrix is converted into numpy array for better view and visibility\n",
    "\n",
    "4.  All the important words in the numpy array have been assigned with weights greater than 0 and all the common words have been assigned with the weights as 0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2afbbf2d",
   "metadata": {},
   "source": [
    "### Step 7:  Divide the dataset into independent and dependent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "id": "3b5ca313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.4472136  0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.4472136  0.4472136  0.         0.         0.         0.4472136\n",
      "  0.4472136  0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.33333333 0.33333333 0.\n",
      "  0.33333333 0.33333333 0.33333333 0.33333333 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.33333333 0.         0.\n",
      "  0.         0.         0.33333333 0.33333333]\n",
      " [0.4472136  0.4472136  0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.4472136  0.4472136\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.4472136  0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.37796447 0.37796447 0.37796447 0.37796447\n",
      "  0.         0.         0.37796447 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.37796447 0.37796447 0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.57735027 0.57735027 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.57735027 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.4472136\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.4472136  0.4472136  0.\n",
      "  0.         0.         0.         0.         0.4472136  0.4472136\n",
      "  0.         0.         0.         0.        ]]\n",
      "0    1\n",
      "1    0\n",
      "2    1\n",
      "3    0\n",
      "4    1\n",
      "5    0\n",
      "Name: sentiment, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "### Independent features \n",
    "\n",
    "X = X_vectorized\n",
    "\n",
    "print(X)\n",
    "\n",
    "### Dependent features\n",
    "\n",
    "Y = df['sentiment']\n",
    "\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "id": "01321de1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "1    3\n",
       "0    3\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 497,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826dfd1d",
   "metadata": {},
   "source": [
    "### Step 8: Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "id": "2ca9c10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size=0.2,random_state=42,stratify=Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "id": "19fde588",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.37796447,\n",
       "        0.37796447, 0.37796447, 0.37796447, 0.        , 0.        ,\n",
       "        0.37796447, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.37796447, 0.37796447, 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.57735027, 0.57735027, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.57735027, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.33333333, 0.33333333,\n",
       "        0.        , 0.33333333, 0.33333333, 0.33333333, 0.33333333,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.33333333, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.33333333, 0.33333333],\n",
       "       [0.4472136 , 0.4472136 , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.4472136 , 0.4472136 , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.4472136 , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 499,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "id": "afe7806f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.       , 0.       , 0.4472136, 0.       , 0.       , 0.       ,\n",
       "        0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "        0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "        0.4472136, 0.4472136, 0.       , 0.       , 0.       , 0.4472136,\n",
       "        0.4472136, 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "        0.       , 0.       , 0.       , 0.       ],\n",
       "       [0.       , 0.       , 0.       , 0.       , 0.       , 0.4472136,\n",
       "        0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "        0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "        0.       , 0.       , 0.       , 0.4472136, 0.4472136, 0.       ,\n",
       "        0.       , 0.       , 0.       , 0.       , 0.4472136, 0.4472136,\n",
       "        0.       , 0.       , 0.       , 0.       ]])"
      ]
     },
     "execution_count": 500,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "id": "bf3e8c86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the input training data is: (4, 34)\n",
      "Shape of the input testing  data is: (2, 34)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of the input training data is:\", X_train.shape)\n",
    "print(\"Shape of the input testing  data is:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "id": "8d929651",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    0\n",
       "4    1\n",
       "1    0\n",
       "2    1\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 502,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "id": "ed81efc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "5    0\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 503,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "id": "6c3868c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the output training data is: (4,)\n",
      "Shape of the output testing  data is: (2,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of the output training data is:\", Y_train.shape)\n",
    "print(\"Shape of the output testing  data is:\", Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01997cd",
   "metadata": {},
   "source": [
    "### OBSERVATIONS:\n",
    "\n",
    "1. After applying the train_test_split function of the input and the output, the data is divided into the training and the testing data.\n",
    "\n",
    "    Training data is 80 %\n",
    "\n",
    "    Testing  data is 20 %."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bce1265",
   "metadata": {},
   "source": [
    "### Step 9: Train Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "id": "0479a1a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-12 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-12 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-12 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-12 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-12 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-12 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-12 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-12 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-12 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-12 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-12 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-12 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-12 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-12 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-12 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-12 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-12 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-12 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-12 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-12 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-12 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-12 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-12 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-12 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-12 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-12\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" checked><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 505,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "### Create the object for Logistic Regression\n",
    "\n",
    "log = LogisticRegression()\n",
    "\n",
    "### using the object for Logistic Regression, train the data\n",
    "\n",
    "log.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e842a50",
   "metadata": {},
   "source": [
    "### OBSERVATIONS:\n",
    "\n",
    "1. First the object for Logistic Regression is created.\n",
    "\n",
    "2. Using the object for Logistic Regression, the model is trained using the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c66c119e",
   "metadata": {},
   "source": [
    "### Step 10: Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "id": "6644d04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = log.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "id": "4e0f72c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1])"
      ]
     },
     "execution_count": 507,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de83d248",
   "metadata": {},
   "source": [
    "### OBSERVATIONS:\n",
    "\n",
    "1. Based on the test data, the predicted output is obtaiend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "id": "a58a65ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "5    0\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 508,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c35d3e",
   "metadata": {},
   "source": [
    "### Step 11: Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "id": "2f5564ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model is: 50.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "ac = accuracy_score(Y_test, Y_pred)*100.0\n",
    "\n",
    "print(\"Accuracy of the model is:\", ac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "id": "60a50daa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix is: [[0 1]\n",
      " [0 1]]\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(Y_test, Y_pred)\n",
    "\n",
    "print(\"Confusion Matrix is:\",cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "id": "48b159d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report is:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       0.50      1.00      0.67         1\n",
      "\n",
      "    accuracy                           0.50         2\n",
      "   macro avg       0.25      0.50      0.33         2\n",
      "weighted avg       0.25      0.50      0.33         2\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\Desktop\\Complete_Data_Science\\vens\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\DELL\\Desktop\\Complete_Data_Science\\vens\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\DELL\\Desktop\\Complete_Data_Science\\vens\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "cr = classification_report(Y_test, Y_pred)\n",
    "\n",
    "print(\"classification report is:\",cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00545116",
   "metadata": {},
   "source": [
    "### Step 12: Predict on New Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "id": "23452a49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
      "\twith 1 stored elements and shape (1, 34)>\n",
      "  Coords\tValues\n",
      "  (0, 23)\t1.0\n",
      "[1]\n",
      "Positive Sentiment 😊\n"
     ]
    }
   ],
   "source": [
    "new_review = [\"This product is really awesome and worth buying\"]\n",
    "\n",
    "### Clean the text\n",
    "\n",
    "cleaned = [clean_text(new_review[0])]\n",
    "\n",
    "### Convert the text into tfidf vector\n",
    "\n",
    "transformed = tfidf.transform(cleaned)\n",
    "\n",
    "print(transformed)\n",
    "\n",
    "### Predict the model\n",
    "\n",
    "predictions = log.predict(transformed)\n",
    "\n",
    "print(predictions)\n",
    "\n",
    "if predictions[0] == 1:\n",
    "    print(\"Positive Sentiment 😊\")\n",
    "else:\n",
    "    print(\"Negative Sentiment 😞\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vens",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
