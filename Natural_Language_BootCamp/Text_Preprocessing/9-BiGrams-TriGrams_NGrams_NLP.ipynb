{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61840344",
   "metadata": {},
   "source": [
    "### BiGrams, TriGrams, NGrams\n",
    "\n",
    "Bi-Grams ------------->  It is the sequence of two consecutive words.\n",
    "\n",
    "Tri-Grams ------------>  It is the sequence of three consecutive words.\n",
    "\n",
    "N-Grams ------------->  It is the sequence of n-consecutive words.\n",
    "\n",
    "\n",
    "### Importance of BiGrams, TriGrams, NGrams\n",
    "\n",
    "1.  It is used for the auto-completion of the sentences.\n",
    "\n",
    "2.  It is used for sentimental analysis\n",
    "\n",
    "3.  It is used for spelling correction\n",
    "\n",
    "4.  It is used for text prediction\n",
    "\n",
    "5. It is used for text similarity\n",
    "\n",
    "6. It is used for Machine Translation.\n",
    "\n",
    "\n",
    "### Steps used in this Algorithm:-\n",
    "\n",
    "1.  Import all the necessary libraries\n",
    "\n",
    "2.  Define the text\n",
    "\n",
    "3.  Peform the tokenization on the text\n",
    "\n",
    "4.  Perform bigram on the text\n",
    "\n",
    "5.  Perform Trigram on the text\n",
    "\n",
    "6.  Pefrom quartergram on the text\n",
    "\n",
    "7.  Pefrom ngram   on the text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff9e099",
   "metadata": {},
   "source": [
    "### Step 1: Import all the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "474a6725",
   "metadata": {},
   "outputs": [],
   "source": [
    "from  nltk  import  word_tokenize, ngrams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e56e03",
   "metadata": {},
   "source": [
    "### OBSERVATIONS:\n",
    "\n",
    "1.  word_tokenize ---------------->  It is used to break the sentences into the words\n",
    "\n",
    "2.  ngrams        ---------------->  It is used to form a sequence of n consecutive words from the tokens."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87fc330",
   "metadata": {},
   "source": [
    "### Step 2: Define the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6ca3aece",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"I love learning data science\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b8a2cc69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I love learning data science'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb43996e",
   "metadata": {},
   "source": [
    "### Step 3: Peform the tokenization on the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "fc919a04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'love', 'learning', 'data', 'science']\n"
     ]
    }
   ],
   "source": [
    "words = word_tokenize(text)\n",
    "\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab3ec95",
   "metadata": {},
   "source": [
    "### Step 4: Perform bigram on the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "018c8c14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('I', 'love'), ('love', 'learning'), ('learning', 'data'), ('data', 'science')]\n"
     ]
    }
   ],
   "source": [
    "from  nltk import ngrams\n",
    "\n",
    "\n",
    "### perform bigram on the text\n",
    "\n",
    "ans = list(ngrams(words,2))\n",
    "\n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dbfa143",
   "metadata": {},
   "source": [
    "### Step 5: Perform Trigram on the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "077c52d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('I', 'love', 'learning'), ('love', 'learning', 'data'), ('learning', 'data', 'science')]\n"
     ]
    }
   ],
   "source": [
    "### perform tri-grams on the tokens\n",
    "\n",
    "ans = list(ngrams(words,3))\n",
    "\n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea9cee5",
   "metadata": {},
   "source": [
    "### Step 6: Perform quartergram on the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0d518e61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('I', 'love', 'learning', 'data'), ('love', 'learning', 'data', 'science')]\n"
     ]
    }
   ],
   "source": [
    "ans = list(ngrams(words,4))\n",
    "\n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569c8753",
   "metadata": {},
   "source": [
    "### Step 7: Perform ngram   on the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "bc29e8ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('I', 'love', 'learning', 'data', 'science')]\n"
     ]
    }
   ],
   "source": [
    "ans = list(ngrams(words,5))\n",
    "\n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f260c62b",
   "metadata": {},
   "source": [
    "### OBSERVATIONS:\n",
    "\n",
    "1. After applying Bi-Grams, Tri-Grams,N-Grams on the tokenized words, a sequence of consecutive words are formed."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vens",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
