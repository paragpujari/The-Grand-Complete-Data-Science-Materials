{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69e19eed",
   "metadata": {},
   "source": [
    "### Calculus "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056fa1a9",
   "metadata": {},
   "source": [
    "### 1. Numerical Derivative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "fbc7fd80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Derivative at x = 3 is: 6.000100000012054\n"
     ]
    }
   ],
   "source": [
    "def f(x):\n",
    "    return(x**2)\n",
    "\n",
    "x = 3\n",
    "\n",
    "h = 0.0001\n",
    "\n",
    "derivative = (f(x+h) - f(x))/h\n",
    "\n",
    "print(\"Derivative at x = 3 is:\", derivative)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b45af06",
   "metadata": {},
   "source": [
    "### 2. Analytical vs Numerical Derivative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "59da1ba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "analytical: 6\n",
      "numerical: 6.000100000012054\n"
     ]
    }
   ],
   "source": [
    "### Depict the Analytical Derivative of f(x) = x**2 is 2x\n",
    "\n",
    "\n",
    "### Analytical Derivative\n",
    "\n",
    "analytical = 2*x    ### As x is 3\n",
    "\n",
    "print(\"analytical:\",analytical)\n",
    "\n",
    "\n",
    "### Numerical Derivative\n",
    "\n",
    "numerical = (f(3+0.0001) - f(3))/0.0001\n",
    "\n",
    "print(\"numerical:\", numerical)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553582f6",
   "metadata": {},
   "source": [
    "### 3. Gradient of a Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "95558cd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1: x = 4.999\n",
      "Iteration 2: x = 4.9980002\n",
      "Iteration 3: x = 4.99700059996\n",
      "Iteration 4: x = 4.996001199840007\n",
      "Iteration 5: x = 4.995001999600039\n"
     ]
    }
   ],
   "source": [
    "### define the gradient of a particular function\n",
    "\n",
    "def gradient(x):\n",
    "    return(2 * x)\n",
    "\n",
    "x = 5\n",
    "learning_rate = 0.0001\n",
    "\n",
    "\n",
    "### Find out the gradient value for 5 samples\n",
    "for i in range(5):\n",
    "    x = x - (learning_rate * gradient(x))\n",
    "    print(f\"Iteration {i+1}: x = {x}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99a6f8a",
   "metadata": {},
   "source": [
    "### 4. Partial Derivatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "050930fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 3\n",
    "\n",
    "y = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "857c8ea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_dx: 6\n",
      "df_dy: 8\n"
     ]
    }
   ],
   "source": [
    "def f(x,y):\n",
    "    return((x**2 + y**2))\n",
    "\n",
    "df_dx = 2*x\n",
    "\n",
    "df_dy = 2*y\n",
    "\n",
    "\n",
    "print(\"df_dx:\", df_dx)\n",
    "\n",
    "print(\"df_dy:\", df_dy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11c9300",
   "metadata": {},
   "source": [
    "### 5. Gradient Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "61ce9615",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "be4c4474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient vector: [6 8]\n"
     ]
    }
   ],
   "source": [
    "def gradient(x, y):\n",
    "    return np.array([2*x, 2*y])\n",
    "\n",
    "point = gradient(3, 4)\n",
    "print(\"Gradient vector:\", point)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9bfb3ab",
   "metadata": {},
   "source": [
    "### 6. Loss Function & Derivative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "6443c1bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient: -8\n"
     ]
    }
   ],
   "source": [
    "# Mean Squared Error loss derivative\n",
    "def mse_derivative(y_true, y_pred, x):\n",
    "    return -2 * x * (y_true - y_pred)\n",
    "\n",
    "y_true = 10\n",
    "y_pred = 8\n",
    "x = 2\n",
    "\n",
    "print(\"Gradient:\", mse_derivative(y_true, y_pred, x))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54d4b96",
   "metadata": {},
   "source": [
    "### 7. Gradient Descent for Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "7dd6ca21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1: w=4.2, loss=64.0\n",
      "Iteration 2: w=4.84, loss=2.5599999999999987\n",
      "Iteration 3: w=4.968, loss=0.10240000000000019\n",
      "Iteration 4: w=4.9936, loss=0.004096000000000008\n",
      "Iteration 5: w=4.99872, loss=0.00016384000000000938\n"
     ]
    }
   ],
   "source": [
    "# y = wx\n",
    "x = 2\n",
    "y = 10\n",
    "w = 1.0\n",
    "lr = 0.1\n",
    "\n",
    "for i in range(5):\n",
    "    y_pred = w * x\n",
    "    loss = (y - y_pred)**2\n",
    "    dw = -2 * x * (y - y_pred)\n",
    "    w = w - lr * dw\n",
    "    print(f\"Iteration {i+1}: w={w}, loss={loss}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vens",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
